{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jare6MPF3DcI",
        "outputId": "b68b3d4e-dfeb-468f-8b6f-ff7204db30ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (13.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (2.1.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (0.17.3)\n",
            "Requirement already satisfied: packaging in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: langchain in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (0.0.326)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (2.0.22)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (3.5.0)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (0.0.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (2.4.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.10.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (4.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: backoff in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (2.2.1)\n",
            "Requirement already satisfied: seqeval in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from seqeval) (1.3.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install backoff\n",
        "!pip install seqeval\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gifN-0wMF7Yz"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "seqeval = evaluate.load(\"seqeval\")\n",
        "\n",
        "def convert_to_iob(d):\n",
        "    for i in range(len(d)):\n",
        "        for j in range(len(d[i])):\n",
        "            if d[i][j] != 'O':\n",
        "                d[i][j] = 'B-' + d[i][j]\n",
        "    return d\n",
        "\n",
        "\n",
        "def compute_metrics_seqeval(gold, predictions):\n",
        "    true_labels_iob = convert_to_iob(gold)\n",
        "    true_predictions_iob = convert_to_iob(predictions)\n",
        "\n",
        "\n",
        "    results = seqeval.compute(predictions=true_predictions_iob, references=true_labels_iob)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519,
          "referenced_widgets": [
            "aff2e5e491db40e7a875c96d746e539c",
            "1c70328f340548f6aedcc0d4e0780e0b",
            "cefd81d7e4a9429bbe13fae45cdc7db3",
            "16c28be2234545e3b2207641be5ea8c5",
            "b2e28bf8074c43e8a00865bb418fb023",
            "c67230e5982c475b997875665729ce12",
            "a44df117298e4e0a90a31d9c865a7ab1",
            "837d7ae5807948218deaf6263dcb494a",
            "c99280649f6c4e4a8b9a99db97b6939f",
            "b99d42dc86d54b6b9195ce7e927c42b6",
            "987b85416ab347368cc55b7fd16ce2ad",
            "caef3a44de9c4e6793753ebe1d139c83"
          ]
        },
        "id": "ybaMrJsAt1I_",
        "outputId": "e09cc69d-826e-4fb5-fbb5-bb0ae1efe57d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['dialogue', 'summary', 'gold_tags'],\n",
            "        num_rows: 100\n",
            "    })\n",
            "})\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "caef3a44de9c4e6793753ebe1d139c83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating Dialog:   0%|          | 0/100 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n",
            "Token match: True\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 118\u001b[0m\n\u001b[1;32m    116\u001b[0m     tag_tokens \u001b[38;5;241m=\u001b[39m output_tag_token\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    117\u001b[0m     output_tokens\u001b[38;5;241m.\u001b[39mappend(tag_tokens[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 118\u001b[0m     output_tags\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtag_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    120\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_output_token_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_tokens)\n\u001b[1;32m    121\u001b[0m record[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_output_tag_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output_tags)\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import os\n",
        "import pandas as pd\n",
        "import datasets\n",
        "import json\n",
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "import openai\n",
        "import backoff  # for exponential backoff\n",
        "\n",
        "TAGS_BEGIN = 'Tags: '\n",
        "\n",
        "@backoff.on_exception(backoff.expo, openai.error.RateLimitError)\n",
        "def get_dialog_turns(chat, prompt, query_text):\n",
        "    dialog_response= {}\n",
        "    dialog_response['Error'] = ''\n",
        "    try:\n",
        "        messages = [\n",
        "            SystemMessage(content=prompt),\n",
        "            HumanMessage(content=query_text)\n",
        "        ]\n",
        "\n",
        "        dialog_message = chat(messages)\n",
        "        dialog_response['text'] = dialog_message.content\n",
        "        dialog_response['success'] = True\n",
        "    except Exception as e:\n",
        "        dialog_response['text'] = ''\n",
        "        dialog_response['success'] = False\n",
        "        dialog_response['Error'] = str(e)\n",
        "\n",
        "    return dialog_response\n",
        "\n",
        "\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] =  \"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\"\n",
        "\n",
        "def get_dialog_query(record):\n",
        "    return f\"Dialog:\\n{record['dialogue']}\\nSummary:\\n{record['summary']}\"\n",
        "\n",
        "ds = load_dataset('Deojoandco/capstone_forgpt_without_gold')\n",
        "print(ds)\n",
        "\n",
        "chat = ChatOpenAI(model_name='gpt-4', temperature=0.0, max_tokens=2048)\n",
        "\n",
        "prompt = '''\n",
        "    Below is a dialog between people and its summary. At the end of summary there is an extra '<EOS>' token. Your task is identify how much the summary is hallucinated. The output should be token by token classification whether its hallucinated or not. Following are the available hallucination classification labels for each token. O : Not Hallucinated, W: Wrong person reference, C: circumstancial error, OB: Object error, N: uncommon error like tense errors. At the end you have to identify if there is any missing information in the summary. For the '<EOS>', the possible labels are either 'M' if the summary has missed any information from the dialog else 'O'.  Remember to tag punctuations and not remove them.\n",
        "\n",
        "Example 1:\n",
        "Dialog: Jesse : I have an idea that'll cheer u up ! Melvin : What is it ? Jesse : I was thinking about doing something 4 the less fortunate this year . Lee : Gr8 idea ! Anything in mind ? Maxine : So no presents 4 me ? : ( Jesse : U'll get ur presents , no worries ; ) Maxine : Phew ! Was getting a bit worried for a moment ; ) Melvin : Bt what do u have in store ? Jesse : Well , have u heard about the Refuge ? Lee : No . What's that ? Melvin : That's the Christmas foundation to help women and children ? Maxine : I think I've heard of them . So what about them ? Jesse : That's right ! They help women and children who escape from abuse . And every year they post wish lists of such ppl online and I thought that we could choose one and chip in . Melvin : That's a great idea ! Lee : Count me in ! Maxine : Me too . Jesse : Have a look at these 3 lists : <file_other> <file_other> <file_other> Lee : I think the second one would be the easiest to arrange . Maxine : Agree . Melvin : What about number 3 ? A bit ambitious , but if we pull together , we'll manage . Jesse : Actually , I'm in for the 3rd one . Maxine : I think the 2nd list would be better . The items cos more or less the same and we can easily divide it . Melvin : But if we agree to chip in the same amount of money , we can deal with the 3rd one easily . Lee : Come to think of it , the 3rd one is not that bad . A bit of planning and logistics and were good to go . Jesse : So it's settled ? Melvin : Yup . Lee : Sure . Maxine : Fine .\n",
        "\n",
        "Summary: Jesse , Lee and Maxine will chip in for the Refuge , a Christmas foundation for women and children who escape from abuse . <EOS>\n",
        "\n",
        "Tags: Jesse(O) ,(O) Lee(O) and(O) Maxine(O) will(O) chip(O) in(O) for(O) the(O) Refuge(O) ,(O) a(O) Christmas(O) foundation(O) for(O) women(O) and(O) children(O) who(O) escape(O) from(O) abuse(O) .(O) <EOS>(O)\n",
        "\n",
        "Example 2:\n",
        "Dialog:\n",
        "Ernest : hey Mike , did you park your car on our street ? Mike : no , took it into garage today Ernest : ok good Mike : why ? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
        "Summary:\n",
        "Mike's car has been damaged beyond repair after being hit by another car . <EOS>\n",
        "\n",
        "Tags: Mike's(W) car(O) has(O) been(O) damaged(O) beyond(C) repair(C) after(O) being(O) hit(O) by(O) another(O) car(O) .(O) <EOS>(M)\n",
        "\n",
        "Looking at the example above please look at the below dialog and its summary. Analyse if the summary is hallucinated and output tags for each token in summary.\n",
        "'''\n",
        "\n",
        "records = []\n",
        "length_matching_golds = []\n",
        "length_matching_preds = []\n",
        "GPT_SUCCESS = 0\n",
        "GPT_OUTPUT_FOUND = 0\n",
        "GPT_OUTPUT_NOT_FOUND = 0\n",
        "\n",
        "pbar = tqdm_notebook(ds['train'], desc='Creating Dialog')\n",
        "for i, record in enumerate(pbar):\n",
        "    query_text = get_dialog_query(record)\n",
        "\n",
        "    dialog_response = get_dialog_turns(chat, prompt, query_text)\n",
        "\n",
        "    record['query'] = prompt + '\\n' + query_text\n",
        "    record['gpt_success'] = dialog_response['success']\n",
        "    record['gpt_response'] = dialog_response['text']\n",
        "\n",
        "    gold_tag_tokens = record['gold_tags'].split()\n",
        "    record['gold_tags_tokens_count'] = len(gold_tag_tokens)\n",
        "\n",
        "    if dialog_response['success'] == True:\n",
        "        GPT_SUCCESS += 1\n",
        "\n",
        "        tags_start_index = record['gpt_response'].find(TAGS_BEGIN)\n",
        "        if tags_start_index != -1:\n",
        "            record['GPT_OUTPUT_FOUND'] = True\n",
        "            GPT_OUTPUT_FOUND += 1\n",
        "\n",
        "            record['gpt_output_tags'] = record['gpt_response'][tags_start_index + len(TAGS_BEGIN):]\n",
        "\n",
        "            output_tag_tokens = record['gpt_output_tags'].split()\n",
        "            record['gpt_output_tag_tokens'] = len(output_tag_tokens)\n",
        "            record['summary_gpt_token_count_match'] = record['gold_tags_tokens_count'] == record['gpt_output_tag_tokens']\n",
        "\n",
        "            output_tokens= []\n",
        "            output_tags = []\n",
        "            for output_tag_token in output_tag_tokens:\n",
        "                tag_tokens = output_tag_token.split('(')\n",
        "                output_tokens.append(tag_tokens[0])\n",
        "                if len(tag_tokens) == 2:\n",
        "                    output_tags.append(tag_tokens[1][:-1])\n",
        "\n",
        "\n",
        "            record['gpt_output_token_count'] = len(output_tokens)\n",
        "            record['gpt_output_tag_count'] = len(output_tags)\n",
        "            record['gpt_output_tags'] = ' '.join(output_tags)\n",
        "\n",
        "            if record['summary_gpt_token_count_match'] == True:\n",
        "                length_matching_golds.append(gold_tag_tokens)\n",
        "                length_matching_preds.append(output_tags)\n",
        "\n",
        "            record['summary_gpt_tags_token_count_match'] = record['gold_tags_tokens_count'] == record['gpt_output_tags']\n",
        "\n",
        "            #print(f\"Token match: {record['summary_gpt_token_count_match']}, tag count match: {record['summary_gpt_tags_token_count_match']}\")\n",
        "\n",
        "        else:\n",
        "          record['GPT_OUTPUT_FOUND'] = False\n",
        "          GPT_OUTPUT_NOT_FOUND += 1\n",
        "\n",
        "\n",
        "    records.append(record)\n",
        "\n",
        "df = pd.DataFrame(data=records)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rirOQauxHvzT",
        "outputId": "5adf88fd-2fda-43b1-e44a-94cfde0e51dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT success Count: 100, Percentage: 100.0\n",
            "Valid GPT output Count: 100, Percentage: 100.0\n",
            "Invalid GPT output Count: 0, Percentage: 0.0\n",
            "Gold and Prediction token length matching. Count: 98, Percentage: 98.0\n",
            "Gold and Prediction token length not matching. Count: 2, Percentage: 2.0\n",
            "{'precision': 0.16666666666666666, 'recall': 0.3333333333333333, 'f1': 0.2222222222222222, 'accuracy': 0.6428571428571429}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ninaadj/opt/anaconda3/envs/cap_proj/lib/python3.9/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "print(f'GPT success Count: {GPT_SUCCESS}, Percentage: {GPT_SUCCESS * 100/len(records)}')\n",
        "\n",
        "print(f'Valid GPT output Count: {GPT_OUTPUT_FOUND}, Percentage: {GPT_OUTPUT_FOUND * 100/len(records)}')\n",
        "print(f'Invalid GPT output Count: {GPT_OUTPUT_NOT_FOUND}, Percentage: {GPT_OUTPUT_NOT_FOUND * 100/len(records)}')\n",
        "\n",
        "print(f'Gold and Prediction token length matching. Count: {len(length_matching_golds)}, Percentage: {len(length_matching_golds) * 100 / len(records)}')\n",
        "\n",
        "not_match_count = len(records) - len(length_matching_golds)\n",
        "print(f'Gold and Prediction token length not matching. Count: {not_match_count}, Percentage: {not_match_count * 100 / len(records)}')\n",
        "\n",
        "score = compute_metrics_seqeval(length_matching_golds, length_matching_preds)\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vs8dfuPXQcR",
        "outputId": "6f5eb4a8-ae94-47f4-a3ae-b984f2b071b6",
        "colab": {
          "referenced_widgets": [
            "b69001ba60534e7ea219e27588ae8e12",
            "dde9b6b4e0ac4984ba758097b41ee341"
          ]
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uploading to Huggingface\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b69001ba60534e7ea219e27588ae8e12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dde9b6b4e0ac4984ba758097b41ee341",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ds = datasets.Dataset.from_pandas(df)\n",
        "\n",
        "# push splits to huggingface repo\n",
        "print(\"Uploading to Huggingface\")\n",
        "ds.push_to_hub('capstone_fromgpt_without_gold', token ='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')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irwCxYUQ-RDL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "16c28be2234545e3b2207641be5ea8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99d42dc86d54b6b9195ce7e927c42b6",
            "placeholder": "​",
            "style": "IPY_MODEL_987b85416ab347368cc55b7fd16ce2ad",
            "value": " 35/100 [1:41:30&lt;4:09:52, 230.66s/it]"
          }
        },
        "1c70328f340548f6aedcc0d4e0780e0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c67230e5982c475b997875665729ce12",
            "placeholder": "​",
            "style": "IPY_MODEL_a44df117298e4e0a90a31d9c865a7ab1",
            "value": "Creating Dialog:  35%"
          }
        },
        "837d7ae5807948218deaf6263dcb494a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "987b85416ab347368cc55b7fd16ce2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a44df117298e4e0a90a31d9c865a7ab1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aff2e5e491db40e7a875c96d746e539c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c70328f340548f6aedcc0d4e0780e0b",
              "IPY_MODEL_cefd81d7e4a9429bbe13fae45cdc7db3",
              "IPY_MODEL_16c28be2234545e3b2207641be5ea8c5"
            ],
            "layout": "IPY_MODEL_b2e28bf8074c43e8a00865bb418fb023"
          }
        },
        "b2e28bf8074c43e8a00865bb418fb023": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b99d42dc86d54b6b9195ce7e927c42b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c67230e5982c475b997875665729ce12": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99280649f6c4e4a8b9a99db97b6939f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cefd81d7e4a9429bbe13fae45cdc7db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_837d7ae5807948218deaf6263dcb494a",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c99280649f6c4e4a8b9a99db97b6939f",
            "value": 35
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}