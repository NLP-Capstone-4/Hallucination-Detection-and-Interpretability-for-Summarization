{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bfb3f14-7161-4734-a832-3a0762d481d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re, json\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_metric,Dataset,DatasetDict, load_dataset, Sequence, Value\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "from jointbart_lmhead_step2 import myBartForConditionalGeneration\n",
    "from hg_utils import GenerationMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c05fd6-23ac-4055-845e-fd2c4fdb835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce90aa0-7033-427e-bc29-ee148a1acc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65402bdf-8983-45b7-b22a-8a576edf5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 256\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9af4c39-926f-407f-893b-346339dba231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"hallucination-tagging-classifier-lmhead\"\n",
    "metric = evaluate.load(\"rouge\")\n",
    "model = myBartForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large\", add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f03ebaed-5107-4492-8d2a-9082efa6b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name == 'classifier.weight' or name == 'classifier.bias':\n",
    "        param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4251206d-463c-42a1-827e-32cb25c25ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('pvisnrt/special_samsum')\n",
    "id2label =  {0: 'C', 1: 'M', 2: 'N', 3: 'O', 4: 'OB', 5: 'W'}\n",
    "label2id = {'C': 0, 'M': 1, 'N': 2, 'O': 3, 'OB': 4, 'W': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b56648b-703d-4b9f-bdff-128e6df29147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87c76e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['train'] = dataset['train'].cast_column(\"tag_ids\", Sequence(Value(\"int32\")))\n",
    "# dataset['validation'] = dataset['validation'].cast_column(\"tag_ids\", Sequence(Value(\"int32\")))\n",
    "# dataset['test'] = dataset['test'].cast_column(\"tag\", Sequence(Value(\"int32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30a31e95-f76f-428d-b5e1-2cc00e7b6e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    inputs = [doc for doc in examples['dialogue']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, is_split_into_words=True, return_tensors='pt', padding='max_length')\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tokenized_inputs = tokenizer(examples[\"summary\"], max_length=max_target_length, truncation=True, is_split_into_words=True, return_tensors='pt', padding='max_length')\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tag_ids\"]):\n",
    "        \n",
    "        \n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)# Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            \n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    model_inputs['labels'] = tokenized_inputs['input_ids']\n",
    "\n",
    "    for i, t in zip(model_inputs['labels'], labels):\n",
    "        if len(i) != len(t):\n",
    "            print(\"Issue\")\n",
    "\n",
    "    model_inputs[\"decoder_tags\"] = labels\n",
    "     \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95cf1276-e3fe-4cb8-9909-c1f813346061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc971df8-5991-4ecc-a970-fb19ffedd4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids', 'input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids', 'input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary', 'tags', 'tag_ids', 'input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2af46311-0248-4620-bab0-c46d17bb4230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns(['id', 'dialogue', 'summary', 'tags', 'tag_ids'])\n",
    "tokenized_datasets['validation'] = tokenized_datasets['validation'].remove_columns(['id', 'dialogue', 'summary', 'tags', 'tag_ids'])\n",
    "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns(['id', 'dialogue', 'summary', 'tags', 'tag_ids'])\n",
    "\n",
    "\n",
    "#tokenized_datasets['train'] = tokenized_datasets['train'].select(range(100))\n",
    "#tokenized_datasets['validation'] = tokenized_datasets['validation'].select(range(20))\n",
    "#tokenized_datasets['test'] = tokenized_datasets['test'].select(range(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d49d5f-d68d-4111-ac74-e97f9e2c4a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c9cecd-5bed-412a-9f60-6afd16f443d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    def prediction_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "        prediction_loss_only: bool,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on `model` using `inputs`.\n",
    "        Subclass and override to inject custom behavior.\n",
    "        Args:\n",
    "            model (`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument `labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "        Return:\n",
    "            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and\n",
    "            labels (each being optional).\n",
    "        \"\"\"\n",
    "        if not self.args.predict_with_generate or prediction_loss_only:\n",
    "            return super().prediction_step(\n",
    "                model, inputs, prediction_loss_only=prediction_loss_only, ignore_keys=ignore_keys\n",
    "            )\n",
    "\n",
    "        has_labels = \"labels\" in inputs\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        \n",
    "        # print(\"prediction_step inputs: {}\".format(inputs.keys()))\n",
    "\n",
    "        # XXX: adapt synced_gpus for fairscale as well\n",
    "        gen_kwargs = self._gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
    "            gen_kwargs[\"max_length\"] = self.model.config.max_length\n",
    "        \n",
    "        # disable beam search\n",
    "        #gen_kwargs[\"num_beams\"] = (\n",
    "        #    gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.model.config.num_beams\n",
    "        #)\n",
    "        \n",
    "        # enable greedy search\n",
    "        gen_kwargs[\"num_beams\"] = 1\n",
    "        gen_kwargs['early_stopping'] = False\n",
    "        \n",
    "        # default_synced_gpus = True if is_deepspeed_zero3_enabled() else False\n",
    "        default_synced_gpus = False\n",
    "        gen_kwargs[\"synced_gpus\"] = (\n",
    "            gen_kwargs[\"synced_gpus\"] if gen_kwargs.get(\"synced_gpus\") is not None else default_synced_gpus\n",
    "        )\n",
    "\n",
    "        if \"attention_mask\" in inputs:\n",
    "            gen_kwargs[\"attention_mask\"] = inputs.get(\"attention_mask\", None)\n",
    "        if \"global_attention_mask\" in inputs:\n",
    "            gen_kwargs[\"global_attention_mask\"] = inputs.get(\"global_attention_mask\", None)\n",
    "\n",
    "        # prepare generation inputs\n",
    "        # some encoder-decoder models can have varying encoder's and thus\n",
    "        # varying model input names\n",
    "        if hasattr(self.model, \"encoder\") and self.model.encoder.main_input_name != self.model.main_input_name:\n",
    "            generation_inputs = inputs[self.model.encoder.main_input_name]\n",
    "        else:\n",
    "            generation_inputs = inputs[self.model.main_input_name]\n",
    "\n",
    "        tags = inputs[\"decoder_tags\"]\n",
    "        gen_kwargs.update({\"decoder_tags\": tags})\n",
    "        # print(f\"Gen kwargs: {gen_kwargs}\")\n",
    "        # print(f\"Gen inputs:{generation_inputs}\")\n",
    "         #generated_tokens = self.model.generate(\n",
    "        #    generation_inputs,\n",
    "        #    **gen_kwargs,\n",
    "        #)\n",
    "        \n",
    "        gen_mix = GenerationMixin(model)\n",
    "        generated_tokens, classification_ids = gen_mix.generate(generation_inputs, **gen_kwargs)\n",
    "        \n",
    "        dialog = tokenizer.batch_decode(generation_inputs, skip_special_tokens=True)\n",
    "        print('-'*89)\n",
    "        print('dialog:\\n', dialog)\n",
    "        \n",
    "        generated_summaries = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        print('\\n\\nGenerated Summaries:\\n',*generated_summaries, sep='\\n')\n",
    "        print(f'Generated summary length: {generated_tokens.shape}')\n",
    "        \n",
    "        classification_labels = []\n",
    "        classification_ids_lst = classification_ids.cpu().detach().tolist()\n",
    "        for batch_classification_ids in classification_ids_lst:\n",
    "            batch_classification_labels = []\n",
    "            for classification_id in batch_classification_ids:\n",
    "                classification_id = classification_id - 3\n",
    "                if classification_id >= 0 and classification_id < len(id2label):\n",
    "                    batch_classification_labels.append(id2label[classification_id])\n",
    "            \n",
    "            classification_labels.append(' '.join(batch_classification_labels))\n",
    "        \n",
    "        print('\\nGenerated Classification Labels:\\n',*classification_labels, sep='\\n')\n",
    "        print(f'Generated classification tag length: {classification_ids.shape}')\n",
    "        \n",
    "       \n",
    "        # in case the batch is shorter than max length, the output should be padded\n",
    "        if gen_kwargs.get(\"max_length\") is not None and generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n",
    "        elif gen_kwargs.get(\"max_new_tokens\") is not None and generated_tokens.shape[-1] < (\n",
    "            gen_kwargs[\"max_new_tokens\"] + 1\n",
    "        ):\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_new_tokens\"] + 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if has_labels:\n",
    "                with self.compute_loss_context_manager():\n",
    "                    outputs = model(**inputs) # lm_logits as output\n",
    "                if self.label_smoother is not None:\n",
    "                    loss = self.label_smoother(outputs, inputs[\"labels\"]).mean().detach()\n",
    "                else:\n",
    "                    loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
    "            else:\n",
    "                loss = None\n",
    "\n",
    "        if self.args.prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        if has_labels:\n",
    "            labels = inputs[\"labels\"]\n",
    "            if gen_kwargs.get(\"max_length\") is not None and labels.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "                labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n",
    "            elif gen_kwargs.get(\"max_new_tokens\") is not None and labels.shape[-1] < (\n",
    "                gen_kwargs[\"max_new_tokens\"] + 1\n",
    "            ):\n",
    "                labels = self._pad_tensors_to_max_len(labels, (gen_kwargs[\"max_new_tokens\"] + 1))\n",
    "        else:\n",
    "            labels = None\n",
    "        # print(labels)\n",
    "\n",
    "        return (loss, generated_tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d87ebd78-55ab-41a5-8086-cb2865a49e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = Seq2SeqTrainingArguments(\n",
    "#     output_dir=\"checkpoints/\",\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=2,\n",
    "#     per_device_eval_batch_size=2,\n",
    "#     weight_decay=0.01,\n",
    "#     save_total_limit=4,\n",
    "#     num_train_epochs=10,\n",
    "#     predict_with_generate=True,\n",
    "#     do_train=True,\n",
    "#     do_eval=True,\n",
    "#     fp16=True,\n",
    "#     logging_steps=1,\n",
    "#     save_strategy=\"epoch\",\n",
    "#     greater_is_better=True,\n",
    "#     metric_for_best_model='Rouge1',\n",
    "#     load_best_model_at_end=True,\n",
    "#     seed=42,\n",
    "#     generation_max_length=max_target_length,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20cb54-5565-4e9e-9bfe-f01169120cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cfb2c32-e9c3-4808-a9a8-1db975df8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoints_lmhead/\",\n",
    "    logging_steps=1,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    seed=42,\n",
    "    generation_max_length=max_target_length,\n",
    "    dataloader_drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "076293cd-d640-4f71-ac7c-6b5ec2147236",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7231598e-f79c-431d-9e52-e0e437f543e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"Generated summary: {decoded_preds[0]}\")\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    print(f\"Gold summary: {decoded_labels[0]}\")\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b8a2f89-e2fc-4efa-9878-3280d7f31f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MySeq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e1dbddf-e03f-4669-87a7-9d0557b74176",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevavratj\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Q4\\capstone\\approach2\\New Approach\\wandb\\run-20231203_210842-5zlzkp2p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/devavratj/huggingface/runs/5zlzkp2p' target=\"_blank\">quiet-paper-95</a></strong> to <a href='https://wandb.ai/devavratj/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/devavratj/huggingface' target=\"_blank\">https://wandb.ai/devavratj/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/devavratj/huggingface/runs/5zlzkp2p' target=\"_blank\">https://wandb.ai/devavratj/huggingface/runs/5zlzkp2p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 07:16, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.622900</td>\n",
       "      <td>4.733024</td>\n",
       "      <td>0.388900</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.319300</td>\n",
       "      <td>26.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.881300</td>\n",
       "      <td>3.887948</td>\n",
       "      <td>0.398700</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.314600</td>\n",
       "      <td>35.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" A : Hi Tom, are you busy tomorrow’s afternoon? B : I’m pretty sure I am. What’s up? A : Can you go with me to the animal shelter?. B : What do you want to do? A : I want to get a puppy for my son. B : That will make him so happy. A : Yeah, we’ve discussed it many times. I think he’s ready now. B : That’s good. Raising a dog is a tough issue. Like having a baby ; -) A : I'll get him one of those little dogs. B : One that won't grow up too big ; -) A : And eat too much ; -)) B : Do you know which one he would like? A : Oh, yes, I took him there last Monday. He showed me one that he really liked. B : I bet you had to drag him away. A : He wanted to take it home right away ; -). B : I wonder what he'll name it. A : He said he’d name it after his dead hamster – Lemmy - he's a great Motorhead fan : -)))\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " A wants to get a puppy for her son. She will take him to the animal shelter tomorrow afternoon. She'll get him one of those little dogs.\n",
      "Generated summary length: torch.Size([1, 34])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 34])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Emma : I’ve just fallen in love with this advent calendar! Awesome! I wanna one for my kids! Rob : I used to get one every year as a child! Loved them! Emma : Yeah, i remember! they were filled with chocolates! Lauren : they are different these days! much more sophisticated! Haha! Rob : yeah, they can be fabric/ wooden, shop bought/ homemade, filled with various stuff Emma : what do you fit inside? Lauren : small toys, Christmas decorations, creative stuff, hair bands & clips, stickers, pencils & rubbers, small puzzles, sweets Emma : WOW! That’s brill! X Lauren : i add one more very special thing as well- little notes asking my children to do something nice for someone else Rob : i like that! My sister adds notes asking her kids questions about christmas such as What did the 3 wise men bring? etc Lauren : i reckon it prepares them for Christmas Emma : and makes it more about traditions and being kind to other people Lauren : my children get very excited every time they get one! Emma : i can see why! : )']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Emma is going to get Rob a Christmas advent calendar for her kids. She wants to fill it with Christmas decorations, Christmas decorations and small Christmas themed items. She will also add notes asking her kids to do something nice for someone else.\n",
      "Generated summary length: torch.Size([1, 50])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 50])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jackie : Madison is pregnant Jackie : but she doesn't wanna talk about it Iggy : why Jackie : I don't know why because she doesn't wanna talk about it Iggy : ok Jackie : I wanted to prepare you for it because people get super excited and ask lots of questions Jackie : and she looked way more anxious than excited Iggy : she's probably worrying about it Iggy : she's taking every commitment really seriously Jackie : it could be money problems or relationship problems Iggy : or maybe she wants an abortion Jackie : it could be all of the above Iggy : but you know what? Iggy : once my friend was pregnant and I couldn't bring myself to be happy about it Jackie : why? Iggy : I felt they were immature and I couldn't picture this couple as parents Jackie : I felt similar way on Patricia's wedding Iggy : Patricia Stevens? Jackie : yes Iggy : so we're talking about the same person Jackie : what a coincidence Jackie : so she's pregnant? Iggy : she thought she was Jackie : damn...\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Jackie is worried about Madison getting pregnant. She wants to talk to Madison about it.\n",
      "Generated summary length: torch.Size([1, 20])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 20])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Marla : <file_photo> Marla : look what I found under my bed Kiki : lol Tamara : is that someone's underwear? Marla : it certainly isn't mine, my ass is big but it isn't huge Kiki : it looks like male underwear Tamara : not necessarily, maybe some butch had fun in your room while you were gone Marla : ok but how can you leave your underwear after hooking up? wtf is wrong with people Kiki : she or he could be too wasted to notice Tamara : or maybe someone put their pants there to piss you off Marla : that makes no sense Marla : it's so fucking childish Kiki : if it's childish then it must have been your sister's idea Marla : she's 13, she doesn't have underwear that isn't pink Tamara : maybe it belonged to one of your exes? Kiki : she would have recognized it Marla : lol we're doing total CSI investigation on one pair of boxers : D Kiki : <file_gif> Tamara : lol Tamara : I think your sister convinced someone to put their underwear in your room as a dare Marla : sounds legit Kiki : Tamara, you just\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Marla found a pair of underwear under her bed. She thinks her sister put it there because she was jealous.\n",
      "Generated summary length: torch.Size([1, 26])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 26])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Robert : Hey give me the address of this music shop you mentioned before Robert : I have to buy guitar cable Fred : <file_other> Fred : Catch it on google maps Robert : thx m8 Fred : ur welcome']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Fred has to buy guitar cable from the music shop Robert mentioned before.\n",
      "Generated summary length: torch.Size([1, 17])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 17])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Keith : Meg, pls buy some milk and cereals, I see now we've run out of them Megan : hm, sure, I can do that Megan : but did you check in the drawer next to the fridge? Keith : nope, let me have a look Keith : ok, false alarm, we have cereal and milk : D Megan : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Megan has cereal and milk, but she hasn't bought them. Keith will buy them.\n",
      "Generated summary length: torch.Size([1, 21])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 21])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Samantha : <file_video> Evelyn : LOL Holly : Is SHE making that noise?? Samatha : Yes (＾▽＾) Holly : How possible?? : o Samantha : Idk, I'm also surprised!! Evelyn : xD\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Samantha is making a noise. Holly is surprised.\n",
      "Generated summary length: torch.Size([1, 13])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 13])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Theresa : have you been at Tom's new place? Luis : yes, it's nice Marion : He invited us for a dinner Adam : where is it? Marion : a bit outside the city Adam : where exactly? Marion : Fiesole Luis : very nice!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Theresa is going to Tom's new place for a dinner.\n",
      "Generated summary length: torch.Size([1, 15])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 15])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jane : Hello Vegano Resto : Hello, how may I help you today? Jane : I would like to make a reservation. Jane : For 6 people, tonight around 20 : 00 Vegano Resto : Let me just check. Vegano Resto : Ah, I'm afraid that there is no room at 20 : 00. Vegano Resto : However, I could offer you a table for six at 18 : 30 or at 21 : 00 Vegano Resto : Would either of those times suit you? Jane : Oh dear. Jane : Let me just ask my friends. Vegano Resto : No problem. Jane : 21 : 00 will be ok. Vegano Resto : Perfect. So tonight at 21 : 00 for six people under your name. Jane : great, thank you!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Jane would like to make a reservation for six people at 21 : 00. Vegano Resto will make the reservation for Jane at 18 : 30. Jane will ask her friends to make the reservations at 21: 00.\n",
      "Generated summary length: torch.Size([1, 47])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 47])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Nancy : Howdy, how y\\'all doin\\'? Tina : Is that a Texan drawl, girl? Nancy : Yes ma\\'am! Loving it out here! Tina : How\\'s the job going? Kids behaving themselves? Nancy : Mostly! They laugh at my accent though! Tina : Well, they probably haven\\'t met a Welsh person before! Nancy : No shit! They ask me to repeat everything! Best one is \"Water\", course, it\\'s mostly \"Waarderr\" here! Tina : LOL. I\\'d love to hear that, you picked up the accent yet? Nancy : Nah, 21 years in Cardiff isn\\'t easily removed! Tina : We\\'re missing you here, the pub is quiet these days without your laugh! Nancy : Miss you too! I\\'m coming home in 6 weeks, though. Last fortnight I\\'m going travelling with 3 other Brits working here, a Geordie girl, a guy from Belfast and Annie, who\\'s from Glasgow. Tina : My God, I\\'m so jealous! I bet they had even more trouble being understood out there! See you after your trip!']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Nancy is working in the pub. She is from Glasgow, and she has a Texan drawl. She's having a lot of trouble being understood because she speaks in a Welsh accent.\n",
      "Generated summary length: torch.Size([1, 41])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 41])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Laura : I need a new printer : / Laura : thinking about this one Laura : <file_other> Jamie : you're sure you need a new one? Jamie : I mean you can buy a second hand one Laura : could be\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Laura is thinking about buying a new printer. Jamie is going to buy a second hand one.\n",
      "Generated summary length: torch.Size([1, 22])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 22])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Barbara : got everything? Haylee : yeah almost Haylee : i'm in dairy section Haylee : but can't find this youghurt u wanted Barbara : the coconut milk one? Haylee : yeah Barbara : hmmm yeah that's a mystery. cause it's not dairy but it's yoghurt xD Haylee : exactly xD Haylee : ok i asked sb. they put it next to eggs lol Barbara : lol\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Haylee is in dairy section and can't find the coconut milk youghurt she wanted. Barbara has looked in the dairy section but she can't locate it.\n",
      "Generated summary length: torch.Size([1, 36])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 36])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Norbert : we need to hurry to catch the tour Wendy : ok, am buying something. be right out! Norbert : ok. am not waiting long though. missed the last one because of you Wendy : just be patient for once. Norbert : im always patient Wendy : at the register now Norbert : alright']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Norbert is buying something. Wendy is buying a ticket.\n",
      "Generated summary length: torch.Size([1, 15])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 15])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Lidia : hi guys, how was your day? Cecil : amazing Lidia : where did you go? Cheryl : to the Jandia Peninsula Cheryl : sorry, Cecil is driving Lidia : and how was it? Cheryl : I liked it a lot Cheryl : Peter took very nice pics Peter : <file_photo> <file_photo> Peter : but it was very windy Lidia : yes, it's always windy here Peter : really? Also in summer? Lidia : sure, the name Fuerteventura means strong wind Cheryl : wow, it's fascinating Lidia : so do you have any plans for tomorrow Cheryl : Cecil wants to explore more the south of the island Peter : I'm just a passenger, so have no voice Cheryl : c'mon, it's not true Peter : I'm just joking Cheryl : we will decide after dinner Cecil : ok, so let me know Cheryl : we will\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Lidia and Cecil went to Fuerteventura on Saturday. Cecil is driving. They went to the Jandia Peninsula.\n",
      "Generated summary length: torch.Size([1, 30])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 30])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Nickola : Have you found it? Sophie : No! Still looking : ( Nickola : Check pockets and handbags. Sophie : Checked them all twice already...']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Sophie is still looking for Nickola's handbag.\n",
      "Generated summary length: torch.Size([1, 14])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 14])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Rosie : What\\'s your favorite b-movie? Elle : um, hard to say. Why do you ask? Dennis : Toxic avenger for sure Rosie : I have to write an essay and I chose bad movies as my topic and I\\'m just looking for inspiration Elle : plan 9 from outer space is definitely something worth mentioning Rosie : Yeah, I\\'ve seen it. And I will also cover \"The Room\". I\\'m just looking for something a bit more niche Dennis : There\\'s Troma Studio for ya - toxic avenger, poultrygeist - the latter is exceptionally awful - and it\\'s a musical Rosie : Is it one of those intentionally bad movies? Dennis : most definitely Rosie : ok, thank you, I\\'ll check it out Elle : oh, there\\'s also jesus christ vampire hunter Rosie : what? : D Elle : it\\'s even worse than it sounds Dennis : and when it comes to more recent movies there are those stupid animal-based horror movies like sharknado or zombeavers Rosie : I\\'ve heard of sharknado and zombeavers sound just awesome Rosie : thanks guys, you helped me a lot : )']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Rosie is going to write an essay about a movie she wants to cover. She will cover toxic avenger, poultrygeist, and vampire hunter. She'll also cover \"The Room\".\n",
      "Generated summary length: torch.Size([1, 42])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 42])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Julia : What is your biggest dream Julia : I mean the kind that can be achieved James : Everyone say I have nice voice James : My mom liked very much when I was reading outloud James : I've had this dream for some time now, to become a voice actor James : Be a part of cartoon or video game as a voice actor reading a character Julia : Wow. Nice one. Julia : Btw you do have a nice voice Julia : I could listen to you as a radio speaker. James : Thanks James : I've worked in radio, but it was during college so I had little time for this Julia : Shame. James : I know. But nothing is lost. I still have microphone at home and with a bit of help I could make homemade radio station Julia : That's actually a great idea Julia : I cheer for you!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " James has a very nice voice. He would like to become a voice actor. He has microphone at home and could make a radio station.\n",
      "Generated summary length: torch.Size([1, 31])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 31])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Poppy : I literally cannot think any more today! Alice : Yeah, I'm in the same shape. What a long day! Poppy : Lunch went by in a flash because I had errands, which makes the day so slow! Alice : I didn't get lunch, so that's even worse! Poppy : Oh, poor you! Aren't you starving? Alice : I'll live. Only three more hours! Poppy : LOL! Not that you're counting... Alice : Damn straight I'm counting! LOL! Poppy : Well, I'm def going for drinks after work. Want to join? Alice : Who else is there? Poppy : Nobody yet but I was going to put the word out. Alice : Sure, sounds fun. I'll invite some people up here if that's okay? Poppy : Oh, got your eye on anyone? Alice : Fred! Poppy : Fred? Really? Alice : Sure, why not? He's single, my age and not bad looking. Poppy : He's a dork! Alice : But a cute one! Poppy : If you say so. Not my type! Alice : That's a relief! Poppy : He's all yours! Alice :\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Poppy is going for drinks after work. Alice is going to invite Fred.\n",
      "Generated summary length: torch.Size([1, 19])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Sash : need to see u Caron : y Caron : i'm out from 12 Sash : will be before Sash : then Caron : k Sash : open the door : Caron : what time u coming I need to go out Sash : soon Caron : hurry up I need to go out\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Caron is going out from 12. She will be out from 11.\n",
      "Generated summary length: torch.Size([1, 18])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 18])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Giuseppe : Hi man Matteo : Yo Giuseppe : How's it going with Gosia? Matteo : I don't know, she's a little strange Giuseppe : Why? Matteo : She always criticizes me because I like football and video games Giuseppe : Damn Matteo : Yeah... Giuseppe : Ok, I don't like games either, but... Matteo : You boring guy Giuseppe : Lol Matteo : Anyway I like her a lot Giuseppe : I can understand that, she's hot, if you ever dump her make sure you tell me Matteo : Get your hands off her, man Giuseppe : Just kidding Matteo : Lollolol\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Matteo is having a bad relationship with Gosia.\n",
      "Generated summary length: torch.Size([1, 14])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 14])\n",
      "Generated summary:  A wants to get a puppy for her son. She will take him to the animal shelter tomorrow afternoon. She'll get him one of those little dogs.\n",
      "Gold summary:  A will go to the animal shelter tomorrow to get a puppy for her son. They already visited the shelter last Monday and the son chose the puppy.\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" A : Hi Tom, are you busy tomorrow’s afternoon? B : I’m pretty sure I am. What’s up? A : Can you go with me to the animal shelter?. B : What do you want to do? A : I want to get a puppy for my son. B : That will make him so happy. A : Yeah, we’ve discussed it many times. I think he’s ready now. B : That’s good. Raising a dog is a tough issue. Like having a baby ; -) A : I'll get him one of those little dogs. B : One that won't grow up too big ; -) A : And eat too much ; -)) B : Do you know which one he would like? A : Oh, yes, I took him there last Monday. He showed me one that he really liked. B : I bet you had to drag him away. A : He wanted to take it home right away ; -). B : I wonder what he'll name it. A : He said he’d name it after his dead hamster – Lemmy - he's a great Motorhead fan : -)))\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " A wants to get a puppy for her son. She wants to take him to the animal shelter to get him one of those little dogs. She will get him a puppy that won't grow up too big. She'll get him the one he wants.\n",
      "Generated summary length: torch.Size([1, 56])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 56])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Emma : I’ve just fallen in love with this advent calendar! Awesome! I wanna one for my kids! Rob : I used to get one every year as a child! Loved them! Emma : Yeah, i remember! they were filled with chocolates! Lauren : they are different these days! much more sophisticated! Haha! Rob : yeah, they can be fabric/ wooden, shop bought/ homemade, filled with various stuff Emma : what do you fit inside? Lauren : small toys, Christmas decorations, creative stuff, hair bands & clips, stickers, pencils & rubbers, small puzzles, sweets Emma : WOW! That’s brill! X Lauren : i add one more very special thing as well- little notes asking my children to do something nice for someone else Rob : i like that! My sister adds notes asking her kids questions about christmas such as What did the 3 wise men bring? etc Lauren : i reckon it prepares them for Christmas Emma : and makes it more about traditions and being kind to other people Lauren : my children get very excited every time they get one! Emma : i can see why! : )']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Emma and Rob want to get an advent calendar for their kids for Christmas. They will fill it with small toys, Christmas decorations, Christmas themed items and Christmas themed questions about the 3 wise men. They also add little notes asking their children to do something nice for someone else.\n",
      "Generated summary length: torch.Size([1, 60])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 60])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jackie : Madison is pregnant Jackie : but she doesn't wanna talk about it Iggy : why Jackie : I don't know why because she doesn't wanna talk about it Iggy : ok Jackie : I wanted to prepare you for it because people get super excited and ask lots of questions Jackie : and she looked way more anxious than excited Iggy : she's probably worrying about it Iggy : she's taking every commitment really seriously Jackie : it could be money problems or relationship problems Iggy : or maybe she wants an abortion Jackie : it could be all of the above Iggy : but you know what? Iggy : once my friend was pregnant and I couldn't bring myself to be happy about it Jackie : why? Iggy : I felt they were immature and I couldn't picture this couple as parents Jackie : I felt similar way on Patricia's wedding Iggy : Patricia Stevens? Jackie : yes Iggy : so we're talking about the same person Jackie : what a coincidence Jackie : so she's pregnant? Iggy : she thought she was Jackie : damn...\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Madison is pregnant. Jackie wants to prepare Iggy for the wedding because she doesn't want to talk about it. She doesn't know why. She's worried about it because she wants an abortion.\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Marla : <file_photo> Marla : look what I found under my bed Kiki : lol Tamara : is that someone's underwear? Marla : it certainly isn't mine, my ass is big but it isn't huge Kiki : it looks like male underwear Tamara : not necessarily, maybe some butch had fun in your room while you were gone Marla : ok but how can you leave your underwear after hooking up? wtf is wrong with people Kiki : she or he could be too wasted to notice Tamara : or maybe someone put their pants there to piss you off Marla : that makes no sense Marla : it's so fucking childish Kiki : if it's childish then it must have been your sister's idea Marla : she's 13, she doesn't have underwear that isn't pink Tamara : maybe it belonged to one of your exes? Kiki : she would have recognized it Marla : lol we're doing total CSI investigation on one pair of boxers : D Kiki : <file_gif> Tamara : lol Tamara : I think your sister convinced someone to put their underwear in your room as a dare Marla : sounds legit Kiki : Tamara, you just\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Marla found a pair of underwear under her bed. She thinks it was someone else's underwear. She believes it was put there by her sister. She doesn't have any underwear that isn't pink.\n",
      "Generated summary length: torch.Size([1, 46])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 46])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Robert : Hey give me the address of this music shop you mentioned before Robert : I have to buy guitar cable Fred : <file_other> Fred : Catch it on google maps Robert : thx m8 Fred : ur welcome']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Fred has to buy guitar cable from the music shop Robert mentioned before.\n",
      "Generated summary length: torch.Size([1, 19])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 19])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Keith : Meg, pls buy some milk and cereals, I see now we've run out of them Megan : hm, sure, I can do that Megan : but did you check in the drawer next to the fridge? Keith : nope, let me have a look Keith : ok, false alarm, we have cereal and milk : D Megan : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Megan has run out of milk and cereals. Keith will buy them for her.\n",
      "Generated summary length: torch.Size([1, 20])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 20])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Samantha : <file_video> Evelyn : LOL Holly : Is SHE making that noise?? Samatha : Yes (＾▽＾) Holly : How possible?? : o Samantha : Idk, I'm also surprised!! Evelyn : xD\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Samatha makes a noise and Holly is surprised.\n",
      "Generated summary length: torch.Size([1, 15])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 15])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Theresa : have you been at Tom's new place? Luis : yes, it's nice Marion : He invited us for a dinner Adam : where is it? Marion : a bit outside the city Adam : where exactly? Marion : Fiesole Luis : very nice!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Theresa and Luis are going to Tom's new place for a dinner.\n",
      "Generated summary length: torch.Size([1, 17])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 17])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jane : Hello Vegano Resto : Hello, how may I help you today? Jane : I would like to make a reservation. Jane : For 6 people, tonight around 20 : 00 Vegano Resto : Let me just check. Vegano Resto : Ah, I'm afraid that there is no room at 20 : 00. Vegano Resto : However, I could offer you a table for six at 18 : 30 or at 21 : 00 Vegano Resto : Would either of those times suit you? Jane : Oh dear. Jane : Let me just ask my friends. Vegano Resto : No problem. Jane : 21 : 00 will be ok. Vegano Resto : Perfect. So tonight at 21 : 00 for six people under your name. Jane : great, thank you!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Jane would like to make a reservation for six people at 21 : 00. Vegano Resto will offer the reservation at 18 : 30 or at 21: 00. Jane will ask her friends to help her.\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Nancy : Howdy, how y\\'all doin\\'? Tina : Is that a Texan drawl, girl? Nancy : Yes ma\\'am! Loving it out here! Tina : How\\'s the job going? Kids behaving themselves? Nancy : Mostly! They laugh at my accent though! Tina : Well, they probably haven\\'t met a Welsh person before! Nancy : No shit! They ask me to repeat everything! Best one is \"Water\", course, it\\'s mostly \"Waarderr\" here! Tina : LOL. I\\'d love to hear that, you picked up the accent yet? Nancy : Nah, 21 years in Cardiff isn\\'t easily removed! Tina : We\\'re missing you here, the pub is quiet these days without your laugh! Nancy : Miss you too! I\\'m coming home in 6 weeks, though. Last fortnight I\\'m going travelling with 3 other Brits working here, a Geordie girl, a guy from Belfast and Annie, who\\'s from Glasgow. Tina : My God, I\\'m so jealous! I bet they had even more trouble being understood out there! See you after your trip!']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Nancy is working in a pub in Cardiff. She and her friends are going travelling in 6 weeks. They are having trouble being understood because of their Welsh accent.\n",
      "Generated summary length: torch.Size([1, 35])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 35])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Laura : I need a new printer : / Laura : thinking about this one Laura : <file_other> Jamie : you're sure you need a new one? Jamie : I mean you can buy a second hand one Laura : could be\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Laura needs a new printer. Jamie suggests she buy a second hand one.\n",
      "Generated summary length: torch.Size([1, 18])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 18])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Barbara : got everything? Haylee : yeah almost Haylee : i'm in dairy section Haylee : but can't find this youghurt u wanted Barbara : the coconut milk one? Haylee : yeah Barbara : hmmm yeah that's a mystery. cause it's not dairy but it's yoghurt xD Haylee : exactly xD Haylee : ok i asked sb. they put it next to eggs lol Barbara : lol\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Haylee is in dairy section and can't find the coconut milk youghurt she wanted. Barbara has it but it's next to eggs.\n",
      "Generated summary length: torch.Size([1, 32])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 32])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Norbert : we need to hurry to catch the tour Wendy : ok, am buying something. be right out! Norbert : ok. am not waiting long though. missed the last one because of you Wendy : just be patient for once. Norbert : im always patient Wendy : at the register now Norbert : alright']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Norbert is buying something. Wendy is buying a ticket for the tour. Norbert will be right out.\n",
      "Generated summary length: torch.Size([1, 27])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 27])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Lidia : hi guys, how was your day? Cecil : amazing Lidia : where did you go? Cheryl : to the Jandia Peninsula Cheryl : sorry, Cecil is driving Lidia : and how was it? Cheryl : I liked it a lot Cheryl : Peter took very nice pics Peter : <file_photo> <file_photo> Peter : but it was very windy Lidia : yes, it's always windy here Peter : really? Also in summer? Lidia : sure, the name Fuerteventura means strong wind Cheryl : wow, it's fascinating Lidia : so do you have any plans for tomorrow Cheryl : Cecil wants to explore more the south of the island Peter : I'm just a passenger, so have no voice Cheryl : c'mon, it's not true Peter : I'm just joking Cheryl : we will decide after dinner Cecil : ok, so let me know Cheryl : we will\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Peter and Cecil went to Fuerteventura today. They went to the Jandia Peninsula and took pictures. They will decide what to do tomorrow.\n",
      "Generated summary length: torch.Size([1, 37])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 37])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Nickola : Have you found it? Sophie : No! Still looking : ( Nickola : Check pockets and handbags. Sophie : Checked them all twice already...']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Sophie has checked all her handbags twice and Nickola is still looking.\n",
      "Generated summary length: torch.Size([1, 18])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 18])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Rosie : What\\'s your favorite b-movie? Elle : um, hard to say. Why do you ask? Dennis : Toxic avenger for sure Rosie : I have to write an essay and I chose bad movies as my topic and I\\'m just looking for inspiration Elle : plan 9 from outer space is definitely something worth mentioning Rosie : Yeah, I\\'ve seen it. And I will also cover \"The Room\". I\\'m just looking for something a bit more niche Dennis : There\\'s Troma Studio for ya - toxic avenger, poultrygeist - the latter is exceptionally awful - and it\\'s a musical Rosie : Is it one of those intentionally bad movies? Dennis : most definitely Rosie : ok, thank you, I\\'ll check it out Elle : oh, there\\'s also jesus christ vampire hunter Rosie : what? : D Elle : it\\'s even worse than it sounds Dennis : and when it comes to more recent movies there are those stupid animal-based horror movies like sharknado or zombeavers Rosie : I\\'ve heard of sharknado and zombeavers sound just awesome Rosie : thanks guys, you helped me a lot : )']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Rosie has to write an essay about bad movies and she wants to cover \"The Room\", \"Toxic avenger\", and \"Zombeavers\". She will also cover \"Plan 9 from outer space\".\n",
      "Generated summary length: torch.Size([1, 46])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 46])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Julia : What is your biggest dream Julia : I mean the kind that can be achieved James : Everyone say I have nice voice James : My mom liked very much when I was reading outloud James : I've had this dream for some time now, to become a voice actor James : Be a part of cartoon or video game as a voice actor reading a character Julia : Wow. Nice one. Julia : Btw you do have a nice voice Julia : I could listen to you as a radio speaker. James : Thanks James : I've worked in radio, but it was during college so I had little time for this Julia : Shame. James : I know. But nothing is lost. I still have microphone at home and with a bit of help I could make homemade radio station Julia : That's actually a great idea Julia : I cheer for you!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " James has a dream to become a voice actor. He wants to be a part of cartoon or video game as a voice artist. He has a microphone at home and could make a radio station. He would like to read out loud to listeners.\n",
      "Generated summary length: torch.Size([1, 54])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 54])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Poppy : I literally cannot think any more today! Alice : Yeah, I'm in the same shape. What a long day! Poppy : Lunch went by in a flash because I had errands, which makes the day so slow! Alice : I didn't get lunch, so that's even worse! Poppy : Oh, poor you! Aren't you starving? Alice : I'll live. Only three more hours! Poppy : LOL! Not that you're counting... Alice : Damn straight I'm counting! LOL! Poppy : Well, I'm def going for drinks after work. Want to join? Alice : Who else is there? Poppy : Nobody yet but I was going to put the word out. Alice : Sure, sounds fun. I'll invite some people up here if that's okay? Poppy : Oh, got your eye on anyone? Alice : Fred! Poppy : Fred? Really? Alice : Sure, why not? He's single, my age and not bad looking. Poppy : He's a dork! Alice : But a cute one! Poppy : If you say so. Not my type! Alice : That's a relief! Poppy : He's all yours! Alice :\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Alice and Poppy are going for drinks after work. They'll invite some people up for drinks. Poppy is going for a drink and he wants to meet up with Fred. Alice is in the same shape.\n",
      "Generated summary length: torch.Size([1, 48])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 48])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Sash : need to see u Caron : y Caron : i'm out from 12 Sash : will be before Sash : then Caron : k Sash : open the door : Caron : what time u coming I need to go out Sash : soon Caron : hurry up I need to go out\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Sash is going out from 12 to see Caron. Caron is out from 11 until 12.\n",
      "Generated summary length: torch.Size([1, 26])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 26])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Giuseppe : Hi man Matteo : Yo Giuseppe : How's it going with Gosia? Matteo : I don't know, she's a little strange Giuseppe : Why? Matteo : She always criticizes me because I like football and video games Giuseppe : Damn Matteo : Yeah... Giuseppe : Ok, I don't like games either, but... Matteo : You boring guy Giuseppe : Lol Matteo : Anyway I like her a lot Giuseppe : I can understand that, she's hot, if you ever dump her make sure you tell me Matteo : Get your hands off her, man Giuseppe : Just kidding Matteo : Lollolol\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Matteo is having a bad relationship with Gosia. He doesn't like football and video games. He's jealous of her because she doesn't play them.\n",
      "Generated summary length: torch.Size([1, 37])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 37])\n",
      "Generated summary:  A wants to get a puppy for her son. She wants to take him to the animal shelter to get him one of those little dogs. She will get him a puppy that won't grow up too big. She'll get him the one he wants.\n",
      "Gold summary:  A will go to the animal shelter tomorrow to get a puppy for her son. They already visited the shelter last Monday and the son chose the puppy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=6.089315139055252, metrics={'train_runtime': 456.2163, 'train_samples_per_second': 0.438, 'train_steps_per_second': 0.438, 'total_flos': 108494205542400.0, 'train_loss': 6.089315139055252, 'epoch': 2.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a8a5a35-5a21-428f-9bed-675645651efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  3 21:16:12 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 Ti   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   42C    P2              36W / 310W |   7944MiB /  8192MiB |     46%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3708      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      6488    C+G   ...on\\119.0.2151.97\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      8500    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9496    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9596    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10328    C+G   ...on\\119.0.2151.97\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     11540    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11812      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12732    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     12884      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     13008    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b088bdf3-6ba2-4198-b1a3-91dfa65018c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "|    0   N/A  N/A     14228    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14496    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14892      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     17444    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     18124    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     18196      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     19052      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Hannah : Hey, do you have Betty's number? Amanda : Lemme check Hannah : <file_gif> Amanda : Sorry, can't find it. Amanda : Ask Larry Amanda : He called her last time we were at the park together Hannah : I don't know him well Hannah : <file_gif> Amanda : Don't be shy, he's very nice Hannah : If you say so.. Hannah : I'd rather you texted him Amanda : Just text him 🙂 Hannah : Urgh.. Alright Hannah : Bye Amanda : Bye bye\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Hannah doesn't know Betty's number. She wants to ask Larry to text him.\n",
      "Generated summary length: torch.Size([1, 22])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 22])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Eric : MACHINE! Rob : That's so gr8! Eric : I know! And shows how Americans see Russian ; ) Rob : And it's really funny! Eric : I know! I especially like the train part! Rob : Hahaha! No one talks to the machine like that! Eric : Is this his only stand-up? Rob : Idk. I'll check. Eric : Sure. Rob : Turns out no! There are some of his stand-ups on youtube. Eric : Gr8! I'll watch them now! Rob : Me too! Eric : MACHINE! Rob : MACHINE! Eric : TTYL? Rob : Sure : )\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Eric will watch Gr8's stand-up. He especially likes the train part.\n",
      "Generated summary length: torch.Size([1, 20])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 20])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Lenny : Babe, can you help me with something? Bob : Sure, what's up? Lenny : Which one should I pick? Bob : Send me photos Lenny : <file_photo> Lenny : <file_photo> Lenny : <file_photo> Bob : I like the first ones best Lenny : But I already have purple trousers. Does it make sense to have two pairs? Bob : I have four black pairs : D : D Lenny : yeah, but shouldn't I pick a different color? Bob : what matters is what you'll give you the most outfit options Lenny : So I guess I'll buy the first or the third pair then Bob : Pick the best quality then Lenny : ur right, thx Bob : no prob : )\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Lenny wants to buy a purple pair of trousers. She has two pairs of black trousers, but she wants to pick the best quality. Bob will help her pick the first pair.\n",
      "Generated summary length: torch.Size([1, 42])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 42])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Will : hey babe, what do you want for dinner tonight? Emma : gah, don't even worry about it tonight Will : what do you mean? everything ok? Emma : not really, but it's ok, don't worry about cooking though, I'm not hungry Will : Well what time will you be home? Emma : soon, hopefully Will : you sure? Maybe you want me to pick you up? Emma : no no it's alright. I'll be home soon, i'll tell you when I get home. Will : Alright, love you. Emma : love you too.\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Will will be home soon. Emma will cook for dinner tonight, but she doesn't want to cook. She's not hungry and she'll tell him when she gets home.\n",
      "Generated summary length: torch.Size([1, 40])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 40])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ollie : Hi, are you in Warsaw Jane : yes, just back! Btw are you free for diner the 19th? Ollie : nope! Jane : and the 18th? Ollie : nope, we have this party and you must be there, remember? Jane : oh right! i lost my calendar.. thanks for reminding me Ollie : we have lunch this week? Jane : with pleasure! Ollie : friday? Jane : ok Jane : what do you mean \" we don\\'t have any more whisky! \" lol.. Ollie : what!!! Jane : you just call me and the all thing i heard was that sentence about whisky... what\\'s wrong with you? Ollie : oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol Jane : dont\\' worry, we\\'ll check on friday. Ollie : don\\'t forget to bring some sun with you Jane : I can\\'t wait to be in Morocco.. Ollie : enjoy and see you friday Jane : sorry Ollie, i\\'m very busy, i won\\'t have time for lunch tomorrow, but may']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Ollie is going to Morocco on Friday for lunch with Jane. They have a party on the 19th and they don't have any more whisky. They will have lunch on the 18th.\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Benjamin : Hey guys, what are we doing with the keys today? Hilary : I've got them. Whoever wants them can meet me at lunchtime or after Elliot : I'm ok. We're meeting for the drinks in the evening anyway and I guess we'll be going back to the apartment together? Hilary : Yeah, I guess so Daniel : I'm with Hilary atm and won't let go of her for the rest of the day, so any option you guys choose is good for me Benjamin : Hmm I might actually pass by at lunchtime, take the keys and go take a nap. I'm sooo tired after yesterday Hilary : Sounds good. We'll be having lunch with some French people (the ones who work on the history of food in colonial Mexico - I already see you yawning your head off) Benjamin : YAAAAWN 🙊 Where and where are you meeting? Hilary : So I'm meeting them at the entrance to the conference hall at 2 pm and then we'll head to this place called La Cantina. Italian cuisine, which is quite funny, but that's what they've chosen Benjamin : Interesting 😱 To be honest, Hilary, I almost feel like changing my mind. Wanting to\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Hilary has the keys to the conference hall at 2 pm and she'll meet some French people for lunch at the entrance to the hall at around 2 pm. They're having Italian cuisine. They'll meet at the conference at 2pm and then go to a place called La Cantina for dinner in the evening. Benjamin will meet Hilary at 2:30 pm and they'll go back to the apartment together for drinks in the early evening.\n",
      "Generated summary length: torch.Size([1, 94])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 94])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Max : Know any good sites to buy clothes from? Payton : Sure : ) <file_other> <file_other> <file_other> <file_other> <file_other> <file_other> <file_other> Max : That's a lot of them! Payton : Yeah, but they have different things so I usually buy things from 2 or 3 of them. Max : I'll check them out. Thanks. Payton : No problem : ) Max : How about u? Payton : What about me? Max : Do u like shopping? Payton : Yes and no. Max : How come? Payton : I like browsing, trying on, looking in the mirror and seeing how I look, but not always buying. Max : Y not? Payton : Isn't it obvious? ; ) Max : Sry ; ) Payton : If I bought everything I liked, I'd have nothing left to live on ; ) Max : Same here, but probably different category ; ) Payton : Lol Max : So what do u usually buy? Payton : Well, I have 2 things I must struggle to resist! Max : Which are? Payton : Clothes, ofc ; ) Max : Right. And the second one? Payton : Books.\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Payton doesn't buy clothes. She only buys clothes from 2 or 3 different sites. She likes browsing, trying on clothes, looking in the mirror and seeing how she looks in the dressing room. She also buys books.\n",
      "Generated summary length: torch.Size([1, 49])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 49])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Rita : I'm so bloody tired. Falling asleep at work. : -( Tina : I know what you mean. Tina : I keep on nodding off at my keyboard hoping that the boss doesn't notice.. Rita : The time just keeps on dragging on and on and on.... Rita : I keep on looking at the clock and there's still 4 hours of this drudgery to go. Tina : Times like these I really hate my work. Rita : I'm really not cut out for this level of boredom. Tina : Neither am I.\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Tina and Rita are both tired at work. Tina is looking at the clock and she keeps nodding off at her keyboard. Rita is bored and she hates her work.\n",
      "Generated summary length: torch.Size([1, 36])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 36])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Beatrice : I am in town, shopping. They have nice scarfs in the shop next to the church. Do you want one? Leo : No, thanks Beatrice : But you don't have a scarf. Leo : Because I don't need it. Beatrice : Last winter you had a cold all the time. A scarf could help. Leo : I don't like them. Beatrice : Actually, I don't care. You will get a scarf. Leo : How understanding of you! Beatrice : You were complaining the whole winter that you're going to die. I've had enough. Leo : Eh.\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Leo doesn't have a scarf. He has a cold and doesn't like scarfs. Beatrice will get him one.\n",
      "Generated summary length: torch.Size([1, 28])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 28])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ivan : hey eric Eric : yeah man Ivan : so youre coming to the wedding Eric : your brother's Ivan : yea Eric : i dont know mannn Ivan : YOU DONT KNOW?? Eric : i just have a lot to do at home, plus i dont know if my parents would let me Ivan : ill take care of your parents Eric : youre telling me you have the guts to talk to them XD Ivan : thats my problem Eric : okay man, if you say so Ivan : yea just be there Eric : alright\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Eric is going to the wedding of his brother's fiance. He wants to go to the ceremony but he doesn't know if his parents will let him go.\n",
      "Generated summary length: torch.Size([1, 37])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 37])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Wanda : Let's make a party! Gina : Why? Wanda : beacuse. I want some fun! Gina : ok, what do u need? Wanda : 1st I need too make a list Gina : noted and then? Wanda : well, could u take yours father car and go do groceries with me? Gina : don't know if he'll agree Wanda : I know, but u can ask : ) Gina : I'll try but theres no promisess Wanda : I know, u r the best! Gina : When u wanna go Wanda : Friday? Gina : ok, I'll ask\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Wanda wants to go out with Gina on Friday. She wants to make a party. Gina will go with her father.\n",
      "Generated summary length: torch.Size([1, 28])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 28])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Martin : I won two cinema tickets! Aggie : oh cool, how come? Martin : online. on fb, the movie mag organized it Aggie : so what did you do Martin : just write a short review and that's it Aggie : well done : ) so what and when. and where? Martin : the new film with Redford Aggie : i guess i heard sth Martin : it's pretty cool i heard. till the end of the week Aggie : sounds good. we'll find time XD\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Martin won two cinema tickets. He'll see Redford in the new film with Robert Redford.\n",
      "Generated summary length: torch.Size([1, 23])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 23])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlee : I'm in class. Theatre in Portuguese lol Curtis : Realllly? Charlee : Yes. One of my subjects at the university that I attend is portuguese theatre. We are preparing a performance Curtis : What performance is this? Are you devising it? Charlee : A polish one translated into portuguese Curtis : Thats quite cool. Who is the writer? Charlee : Mrożek\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Charlee is in class. She is preparing a performance in Portuguese. She has a polish one translated into portuguese.\n",
      "Generated summary length: torch.Size([1, 28])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 28])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : Are you going by car or train? Tom : Ella rented a car Ella : this makes all of this much faster Mary : good decision']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Ella rented a car. Mary is going by car.\n",
      "Generated summary length: torch.Size([1, 17])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 17])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Luke : are you still looking for someone to join netflix family? Paul : yes, 1 person : ) Luke : i am the one! Paul : sure, i will send you the login and password on sunday Luke : ok we can talk tomorrow Paul : i don't really remember it now Luke : send me also the bank account details so I can wire you the money every month. Are you paying for this or someone else? Paul : I do, and I keep track of everyone accessing so you should not expect any bans : D Luke : easy mate : D you still on holidays with your girl? Paul : last dinner : ( tomorrow we are out Luke : how long have you been there? Paul : less than 8 days : /\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Paul is still on holidays with his girl and he is looking for someone to join netflix family. Luke will send him the login and password on sunday. Paul will send the bank account details so he can wire the money every month.\n",
      "Generated summary length: torch.Size([1, 53])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 53])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Greg : Hi, honey. I need to stay after hours : -( Betsy : Again? Greg : I'm sorry! Betsy : What about Johnny? Greg : Well, could you pick him up? Betsy : What if I can't? Greg : Betsy? Betsy : What if I can't? Greg : Can't you, really? Betsy : I can't. Today I need to work long hours as well. Tuesdays are your days in the kindergarten. Greg : Talk to you later. I'll see what I can do. Betsy : You'd better think of something. Greg : Oh. Just stop it now.\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Betsy can't pick up Johnny from school on Tuesdays. She has to work long hours and she needs to stay after hours. She can't because she has to pick up her son from school.\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Ethan and Toby are making fun of Scott. They're making fun because they know he's exactly the same as Toby.\n",
      "Generated summary length: torch.Size([1, 29])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 29])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Igor : Shit, I've got so much to do at work and I'm so demotivated. John : It's pretty irresponsible to give that much work to someone on their notice period. Igor : Yeah, exactly! Should I even care? John : It's up to you, but you know what they say... Igor : What do you mean? John : Well, they say how you end things shows how you really are... Igor : And now how you start, right? John : Gotcha! Igor : So what shall I do then? John : It's only two weeks left, so grit your teeth and do what you have to do. Igor : Easy to say, hard to perform. John : Come on, stop thinking, start doing! Igor : That's so typical of you! ; )\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Igor has two weeks left to finish work at work. He's depressed and has so much to do. John will help him.\n",
      "Generated summary length: torch.Size([1, 29])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 29])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Clara : Hi, what you up to? Neela : Not much, chilling out. Clara : Just rewatching Dear White People on Netflix, love it! 😍 Neela : Oh yeah, heard of it, but not seen it yet? Any good? Clara : Well, yes! I just said it was, LOL. It's about a fictional Ivy League University and the students in one House of Residence. Neela : Why is it called Dear White People? Clara : That's the name of the radio show the main character, Sam, presents on college radio. Neela : Yeah, but why is it so good? Clara : Well, it's mainly stories from the perspective of black students there, which I find very interesting. The characters are strong and likeable too. Neela : I suppose it's rather different from the UK, then? Clara : It seems so, as there is a lot more racial awareness and discrimination there than here. It all kicks off when there is a Blackface party held by an elite group of white students, which gets out of hand. Neela : How's that? Clara : Well, obviously, the black students try to break it up and there's also an incident where one guy, Reggie,\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Clara and Neela are having a relaxing day. They are watching Dear White People on Netflix. They both like it and it's about a fictional Ivy League University and the students in one House of Residence. Clara and her friends are black and they are very interested in the fictional characters.\n",
      "Generated summary length: torch.Size([1, 61])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 61])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      " Mike took his car into garage today. Someone just crashed into it.\n",
      "Generated summary length: torch.Size([1, 17])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 17])\n",
      "Generated summary:  Hannah doesn't know Betty's number. She wants to ask Larry to text him.\n",
      "Gold summary:  Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.7750210762023926,\n",
       " 'eval_rouge1': 0.4314,\n",
       " 'eval_rouge2': 0.1833,\n",
       " 'eval_rougeL': 0.3326,\n",
       " 'eval_rougeLsum': 0.3321,\n",
       " 'eval_gen_len': 37.15,\n",
       " 'eval_runtime': 50.9579,\n",
       " 'eval_samples_per_second': 0.392,\n",
       " 'eval_steps_per_second': 0.392,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7452b49-20dd-402e-927a-9bce70e4fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"summarizer_w_classifier_loss_frozen_lmhead\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
