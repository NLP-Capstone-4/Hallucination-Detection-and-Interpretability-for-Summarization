{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1dcee7c-0363-40b2-8a67-1cae64898c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re, json\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_metric,Dataset,DatasetDict, load_dataset, Sequence, Value\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "from jointbart_step1 import myBartForConditionalGeneration\n",
    "from jointbart_lmhead_step2 import myBartForConditionalGeneration\n",
    "from hg_utils import GenerationMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899f8323-f0cd-4591-a7fc-3d0d37aca400",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7214fe4b-67d9-4614-8635-bb95efe58623",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48ae316-d6f6-40fa-8bb3-378e03d1eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iob(d):\n",
    "    for i in range(len(d)):\n",
    "        for j in range(len(d[i])):\n",
    "            if d[i][j] != 'O':\n",
    "                d[i][j] = 'B-' + d[i][j]\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150af1a2-0059-44ef-ae69-7563650a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-large\"\n",
    "metric = evaluate.load(\"rouge\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ae69bd-d3eb-4e28-b10a-3d30d3962e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 256\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7781f554-4604-4ff1-b9b2-fc5a998bc09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of myBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = myBartForConditionalGeneration.from_pretrained(model_checkpoint).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f8cbea-454a-4bd9-b850-56ba4977aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name == 'classifier.weight' or name == 'classifier.bias':\n",
    "        continue\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d9e4db0-eac9-42a8-94ad-7df8e88e2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('pvisnrt/mod_capstone')\n",
    "id2label =  {0: 'C', 1: 'M', 2: 'N', 3: 'O', 4: 'OB', 5: 'W'}\n",
    "label2id = {'C': 0, 'M': 1, 'N': 2, 'O': 3, 'OB': 4, 'W': 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376eef20-c4b0-44f4-8810-0622bc39cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d5c2a7-e585-4a77-8b09-bd16b68d9e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afa59124-159c-442d-890f-9c0eb570f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].cast_column(\"tags\", Sequence(Value(\"int64\")))\n",
    "dataset['validation'] = dataset['validation'].cast_column(\"tags\", Sequence(Value(\"int64\")))\n",
    "dataset['test'] = dataset['test'].cast_column(\"tags\", Sequence(Value(\"int64\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257738f7-0da2-4f96-8d3f-8a8500577bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'summary_target': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'tags': Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e73fb4-5b3e-4ae7-b1d6-83f5835e386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    inputs = [doc for doc in examples['source']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, is_split_into_words=True, return_tensors='pt', padding=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tokenized_inputs = tokenizer(examples[\"summary_target\"], truncation=True, is_split_into_words=True, return_tensors='pt', padding=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)# Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            \n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    model_inputs['labels'] = tokenized_inputs['input_ids']\n",
    "\n",
    "    model_inputs[\"decoder_tags\"] = labels\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42855419-2f1d-4c20-bd68-ab82d2c6f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2462a5d2-6415-4342-811d-765089e25a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns(['source','summary_target', 'tags'])\n",
    "tokenized_datasets['validation'] = tokenized_datasets['validation'].remove_columns(['source','summary_target', 'tags'])\n",
    "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns(['source','summary_target', 'tags'])\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ee65ba8-4816-447e-8e2c-8767959e4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    def prediction_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "        prediction_loss_only: bool,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on `model` using `inputs`.\n",
    "        Subclass and override to inject custom behavior.\n",
    "        Args:\n",
    "            model (`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument `labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "        Return:\n",
    "            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and\n",
    "            labels (each being optional).\n",
    "        \"\"\"\n",
    "        if not self.args.predict_with_generate or prediction_loss_only:\n",
    "            return super().prediction_step(\n",
    "                model, inputs, prediction_loss_only=prediction_loss_only, ignore_keys=ignore_keys\n",
    "            )\n",
    "\n",
    "        has_labels = \"labels\" in inputs\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        \n",
    "        # print(\"prediction_step inputs: {}\".format(inputs.keys()))\n",
    "\n",
    "        # XXX: adapt synced_gpus for fairscale as well\n",
    "        gen_kwargs = self._gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
    "            gen_kwargs[\"max_length\"] = self.model.config.max_length\n",
    "        \n",
    "        # disable beam search\n",
    "        #gen_kwargs[\"num_beams\"] = (\n",
    "        #    gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.model.config.num_beams\n",
    "        #)\n",
    "        \n",
    "        # enable greedy search\n",
    "        gen_kwargs[\"num_beams\"] = 1\n",
    "        gen_kwargs['early_stopping'] = False\n",
    "        \n",
    "        # default_synced_gpus = True if is_deepspeed_zero3_enabled() else False\n",
    "        default_synced_gpus = False\n",
    "        gen_kwargs[\"synced_gpus\"] = (\n",
    "            gen_kwargs[\"synced_gpus\"] if gen_kwargs.get(\"synced_gpus\") is not None else default_synced_gpus\n",
    "        )\n",
    "\n",
    "        if \"attention_mask\" in inputs:\n",
    "            gen_kwargs[\"attention_mask\"] = inputs.get(\"attention_mask\", None)\n",
    "        if \"global_attention_mask\" in inputs:\n",
    "            gen_kwargs[\"global_attention_mask\"] = inputs.get(\"global_attention_mask\", None)\n",
    "\n",
    "        # prepare generation inputs\n",
    "        # some encoder-decoder models can have varying encoder's and thus\n",
    "        # varying model input names\n",
    "        if hasattr(self.model, \"encoder\") and self.model.encoder.main_input_name != self.model.main_input_name:\n",
    "            generation_inputs = inputs[self.model.encoder.main_input_name]\n",
    "        else:\n",
    "            generation_inputs = inputs[self.model.main_input_name]\n",
    "\n",
    "        tags = inputs[\"decoder_tags\"]\n",
    "        gen_kwargs.update({\"decoder_tags\": tags})\n",
    "        # print(f\"Gen kwargs: {gen_kwargs}\")\n",
    "        # print(f\"Gen inputs:{generation_inputs}\")\n",
    "         #generated_tokens = self.model.generate(\n",
    "        #    generation_inputs,\n",
    "        #    **gen_kwargs,\n",
    "        #)\n",
    "        \n",
    "        gen_mix = GenerationMixin(model)\n",
    "        generated_tokens, classification_ids = gen_mix.generate(generation_inputs, **gen_kwargs)\n",
    "        \n",
    "        dialog = tokenizer.batch_decode(generation_inputs, skip_special_tokens=True)\n",
    "        print('-'*89)\n",
    "        print('dialog:\\n', dialog)\n",
    "        \n",
    "        generated_summaries = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        print('\\n\\nGenerated Summaries:\\n',*generated_summaries, sep='\\n')\n",
    "        print(f'Generated summary length: {generated_tokens.shape}')\n",
    "        \n",
    "        classification_labels = []\n",
    "        classification_ids_lst = classification_ids.cpu().detach().tolist()\n",
    "        for batch_classification_ids in classification_ids_lst:\n",
    "            batch_classification_labels = []\n",
    "            for classification_id in batch_classification_ids:\n",
    "                classification_id = classification_id - 3\n",
    "                if classification_id >= 0 and classification_id < len(id2label):\n",
    "                    batch_classification_labels.append(id2label[classification_id])\n",
    "            \n",
    "            classification_labels.append(' '.join(batch_classification_labels))\n",
    "        \n",
    "        print('\\nGenerated Classification Labels:\\n',*classification_labels, sep='\\n')\n",
    "        print(f'Generated classification tag length: {classification_ids.shape}')\n",
    "        \n",
    "       \n",
    "        # in case the batch is shorter than max length, the output should be padded\n",
    "        if gen_kwargs.get(\"max_length\") is not None and generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n",
    "        elif gen_kwargs.get(\"max_new_tokens\") is not None and generated_tokens.shape[-1] < (\n",
    "            gen_kwargs[\"max_new_tokens\"] + 1\n",
    "        ):\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_new_tokens\"] + 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if has_labels:\n",
    "                with self.compute_loss_context_manager():\n",
    "                    outputs = model(**inputs) # lm_logits as output\n",
    "                if self.label_smoother is not None:\n",
    "                    loss = self.label_smoother(outputs, inputs[\"labels\"]).mean().detach()\n",
    "                else:\n",
    "                    loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
    "            else:\n",
    "                loss = None\n",
    "\n",
    "        if self.args.prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        if has_labels:\n",
    "            labels = inputs[\"labels\"]\n",
    "            if gen_kwargs.get(\"max_length\") is not None and labels.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "                labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n",
    "            elif gen_kwargs.get(\"max_new_tokens\") is not None and labels.shape[-1] < (\n",
    "                gen_kwargs[\"max_new_tokens\"] + 1\n",
    "            ):\n",
    "                labels = self._pad_tensors_to_max_len(labels, (gen_kwargs[\"max_new_tokens\"] + 1))\n",
    "        else:\n",
    "            labels = None\n",
    "        # print(labels)\n",
    "\n",
    "        return (loss, generated_tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da4e823b-e3d8-4b68-8a49-d327b130d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoints_lmhead/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=4,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42,\n",
    "    generation_max_length=max_target_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12bd51c9-2099-497d-8c34-945230f12dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0fd3626-cfd1-4b71-b11c-64792462b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "\n",
    "    print(\"In compute metrics\")\n",
    "\n",
    "    print(predictions[0])\n",
    "\n",
    "    print(labels[0])\n",
    "    \n",
    "    preds = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    # print(preds[0])\n",
    "    flattened_preds = [item for sublist in preds for item in sublist]\n",
    "    # decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # print(decoded_preds\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # print(labels[0])\n",
    "    flattened_labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "    result = f1_metric.compute(predictions=flattened_preds, references=flattened_labels, average='micro')\n",
    "    # decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # print(\"Decoded preds and labels\")\n",
    "\n",
    "    # print(decoded_preds)\n",
    "    # print(decoded_labels)\n",
    "    \n",
    "    # # Rouge expects a newline after each sentence\n",
    "    # decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    # decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    print(result.items())\n",
    "    #result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    # result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab5cfb3f-6f29-40de-9f69-f421aac7e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MySeq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "412a0500-60d1-4124-b02a-8a1eb92c4721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myBartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50265, bias=False)\n",
       "  (classifier): Linear(in_features=50265, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df0508f1-b851-4c58-b532-df53b04932ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdevavratj\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>D:\\Q4\\capstone\\approach2\\New Approach\\wandb\\run-20231203_205940-qhulnb32</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/devavratj/huggingface/runs/qhulnb32' target=\"_blank\">snowy-shape-94</a></strong> to <a href='https://wandb.ai/devavratj/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/devavratj/huggingface' target=\"_blank\">https://wandb.ai/devavratj/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/devavratj/huggingface/runs/qhulnb32' target=\"_blank\">https://wandb.ai/devavratj/huggingface/runs/qhulnb32</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 04:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.932500</td>\n",
       "      <td>11.666988</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>21.536200</td>\n",
       "      <td>11.407684</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.051700</td>\n",
       "      <td>11.530451</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>14.947400</td>\n",
       "      <td>11.317176</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>22.830700</td>\n",
       "      <td>11.260351</td>\n",
       "      <td>0.168800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true Adam : She was telling me she doesn't feel like doing anything, she's bored all the time, she never feels happy. It sounds like a real, typical depression Adam : She also told me that she has trouble sleeping. I asked her to go out for a beer or anything basically, but she doesn't want to leave the flat Karen : Oh my, it sounds really serious. I don't what to tell you Adam : I was wondering how I can help her Karen : Honestly I don't know if we can help her, Adam. I suggested a specialist because these are very sensitive issues and I'm afraid we may unintentionally make it worse Adam : Yes, but she doesn't want to see a specialist. Basically, she doesn't want to see anyone Karen : Hm... I don't know\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Adam : I'm going to ask you a question, Karen, I'm wondering if you can help me with something, I think I need to talk to you about something. Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Scott : you know you're exactly fuckin the same. Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you're almost fuckin the exact same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file-gif>\n",
      "Generated summary length: torch.Size([1, 80])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O M O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 80])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O OB O O O O O O O O O O O O O O O O O O O O O O O C C O O O O O O O O O O O C O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mike : hey Ernest, I just got a call from my neighbor. Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
      "Generated summary length: torch.Size([1, 67])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O W O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 67])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlotte : Hello Paula, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'nu' as in 'number'. Charlotte : And the stress on the second syllable? Or the first? Paula : 2nd Charlotte : Thank you dear. Paula : <file_other> Charlotte : Lovely to hear your voice!! Paula : : $ Paula : <file_other> Charlotte : : X\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Charlotte : Hello Paula, I'm so glad to hear your voice! Paula : <file_other> Charlotte : Thank you dear. Paula : : X. Charlotte : Hello Charlotte, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'na' as the first syllable? Or the first? Paula: 2nd Charlotte : And the stress on the second syllable : '\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O N O O O O O O O O O O O O O O O O W O O O O O O O OB O O O O W O N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdre, I'm been meaning to message you, had a favour to ask. Deirdre : Wondered if you had any thought about your Mum's 40th, we've got to do something special! Beth : How about a girls weekend, just mum, me, you and the girls, Kira will have to come back from Uni, of course. Deirdre : Sounds fab! Get your thinking cap on, it's only in 6 weeks! Bet she's dreading it, I remember doing that! Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdre : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies! What was the favour, darling? Beth : Oh, it was just that I fancied trying a bit of work experience in the salon, auntie. Deirdre : Well, I am looking for Saturday girls, are you sure about it? you could do well in the exams and go on to college or 6th form. Beth : I know, but it's not for me, auntie, I am doing all\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Beth : Hi, I'm Beth, I've been meaning to message you, had a favour to ask. Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdres, I haven't been in for a while, I just wanted to say hello. Deirdree : Hi I'm Deirdrea, I was just thinking about you, Beth. Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdle : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies!\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O OB C O O O O O O O O O O O O O O O OB C O O O O O O O O O O O O O O O O O O OB C O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O OB C O O O O O O O O O O O O O O O O C O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24671  4832    38   437   164     7  1394    47    10   864\n",
      "  2156  7836  2156    38   437  8020   114    47    64   244   162    19\n",
      "   402  2156    38   206    38   240     7  1067     7    47    59   402\n",
      "     4  3086  4832  6319    47  3244     7   392 17487  7836  4832  3216\n",
      "  2156  2350  2156   596 17487  3086  4832    38    95  3244     7    69\n",
      "     8    38   531  8109    38  4022    59    69  7836  4832  1464   350\n",
      "  2156    38  2528    79   197   192    10  6857  2156    53    79   938\n",
      "    75   182  1372    59    24  3086  4832   440  5170   479   479   479\n",
      "  7836  4832    38   216  2156    53    38   206    42    16  1473   479\n",
      "   264    18   584    79    18 16658  2156   101   961   198  2156    53\n",
      "    11    69   403    24   189    28  1528     2]\n",
      "[    0  3086  3244     7   392    59    69  6943   479   264   630    75\n",
      "   236     7   192    10  6857   479  7836  3649  1765    10 19902   479\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.16875)])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true Adam : She was telling me she doesn't feel like doing anything, she's bored all the time, she never feels happy. It sounds like a real, typical depression Adam : She also told me that she has trouble sleeping. I asked her to go out for a beer or anything basically, but she doesn't want to leave the flat Karen : Oh my, it sounds really serious. I don't what to tell you Adam : I was wondering how I can help her Karen : Honestly I don't know if we can help her, Adam. I suggested a specialist because these are very sensitive issues and I'm afraid we may unintentionally make it worse Adam : Yes, but she doesn't want to see a specialist. Basically, she doesn't want to see anyone Karen : Hm... I don't know\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Adam : I'm going to ask you a question, Karen, I'm wondering if you can help me with something, I think I need to talk to you about something. Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O N O N O O O O O O O N O O O C O O N O O O O C O O O O O O O O O O C C N O O O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O O O O O C O O C C O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Scott : you know you're exactly fuckin the same. Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you're almost fuckin the exact same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file-gif>\n",
      "Generated summary length: torch.Size([1, 80])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O W O O O O M O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O O W O O C O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 80])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C C O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C C C O O O O O O O O O O C O O W O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mike : hey Ernest, I just got a call from my neighbor. Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
      "Generated summary length: torch.Size([1, 67])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O O O O O O O O O O O O O O O O O O C O C C O O O O O W W O O O C O\n",
      "Generated classification tag length: torch.Size([1, 67])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlotte : Hello Paula, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'nu' as in 'number'. Charlotte : And the stress on the second syllable? Or the first? Paula : 2nd Charlotte : Thank you dear. Paula : <file_other> Charlotte : Lovely to hear your voice!! Paula : : $ Paula : <file_other> Charlotte : : X\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Charlotte : Hello Paula, I'm so glad to hear your voice! Paula : <file_other> Charlotte : Thank you dear. Paula : : X. Charlotte : Hello Charlotte, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'na' as the first syllable? Or the first? Paula: 2nd Charlotte : And the stress on the second syllable : '\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O N O O O O O O O C C O W O O O O O O O OB O O O O C N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdre, I'm been meaning to message you, had a favour to ask. Deirdre : Wondered if you had any thought about your Mum's 40th, we've got to do something special! Beth : How about a girls weekend, just mum, me, you and the girls, Kira will have to come back from Uni, of course. Deirdre : Sounds fab! Get your thinking cap on, it's only in 6 weeks! Bet she's dreading it, I remember doing that! Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdre : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies! What was the favour, darling? Beth : Oh, it was just that I fancied trying a bit of work experience in the salon, auntie. Deirdre : Well, I am looking for Saturday girls, are you sure about it? you could do well in the exams and go on to college or 6th form. Beth : I know, but it's not for me, auntie, I am doing all\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Beth : Hi, I'm Beth, I've been meaning to message you, had a favour to ask. Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdres, I haven't been in for a while, I just wanted to say hello. Deirdree : Hi I'm Deirdrea, I was just thinking about you, Beth. Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdle : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies!\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O OB C O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O C O C O O O O OB C O O O O O N O O O O O O C C C C O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24671  4832    38   437   164     7  1394    47    10   864\n",
      "  2156  7836  2156    38   437  8020   114    47    64   244   162    19\n",
      "   402  2156    38   206    38   240     7  1067     7    47    59   402\n",
      "     4  3086  4832  6319    47  3244     7   392 17487  7836  4832  3216\n",
      "  2156  2350  2156   596 17487  3086  4832    38    95  3244     7    69\n",
      "     8    38   531  8109    38  4022    59    69  7836  4832  1464   350\n",
      "  2156    38  2528    79   197   192    10  6857  2156    53    79   938\n",
      "    75   182  1372    59    24  3086  4832   440  5170   479   479   479\n",
      "  7836  4832    38   216  2156    53    38   206    42    16  1473   479\n",
      "   264    18   584    79    18 16658  2156   101   961   198  2156    53\n",
      "    11    69   403    24   189    28  1528     2]\n",
      "[    0  3086  3244     7   392    59    69  6943   479   264   630    75\n",
      "   236     7   192    10  6857   479  7836  3649  1765    10 19902   479\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.16875)])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true Adam : She was telling me she doesn't feel like doing anything, she's bored all the time, she never feels happy. It sounds like a real, typical depression Adam : She also told me that she has trouble sleeping. I asked her to go out for a beer or anything basically, but she doesn't want to leave the flat Karen : Oh my, it sounds really serious. I don't what to tell you Adam : I was wondering how I can help her Karen : Honestly I don't know if we can help her, Adam. I suggested a specialist because these are very sensitive issues and I'm afraid we may unintentionally make it worse Adam : Yes, but she doesn't want to see a specialist. Basically, she doesn't want to see anyone Karen : Hm... I don't know\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Adam : I'm going to ask you a question, Karen, I'm wondering if you can help me with something, I think I need to talk to you about something. Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Scott : you know you're exactly fuckin the same. Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you're almost fuckin the exact same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file-gif>\n",
      "Generated summary length: torch.Size([1, 80])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O M O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 80])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O C O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mike : hey Ernest, I just got a call from my neighbor. Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
      "Generated summary length: torch.Size([1, 67])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 67])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlotte : Hello Paula, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'nu' as in 'number'. Charlotte : And the stress on the second syllable? Or the first? Paula : 2nd Charlotte : Thank you dear. Paula : <file_other> Charlotte : Lovely to hear your voice!! Paula : : $ Paula : <file_other> Charlotte : : X\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Charlotte : Hello Paula, I'm so glad to hear your voice! Paula : <file_other> Charlotte : Thank you dear. Paula : : X. Charlotte : Hello Charlotte, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'na' as the first syllable? Or the first? Paula: 2nd Charlotte : And the stress on the second syllable : '\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O OB O O O O O N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdre, I'm been meaning to message you, had a favour to ask. Deirdre : Wondered if you had any thought about your Mum's 40th, we've got to do something special! Beth : How about a girls weekend, just mum, me, you and the girls, Kira will have to come back from Uni, of course. Deirdre : Sounds fab! Get your thinking cap on, it's only in 6 weeks! Bet she's dreading it, I remember doing that! Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdre : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies! What was the favour, darling? Beth : Oh, it was just that I fancied trying a bit of work experience in the salon, auntie. Deirdre : Well, I am looking for Saturday girls, are you sure about it? you could do well in the exams and go on to college or 6th form. Beth : I know, but it's not for me, auntie, I am doing all\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Beth : Hi, I'm Beth, I've been meaning to message you, had a favour to ask. Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdres, I haven't been in for a while, I just wanted to say hello. Deirdree : Hi I'm Deirdrea, I was just thinking about you, Beth. Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdle : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies!\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O OB C O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O OB C O O O O O O O O O O O O O O O O C O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24671  4832    38   437   164     7  1394    47    10   864\n",
      "  2156  7836  2156    38   437  8020   114    47    64   244   162    19\n",
      "   402  2156    38   206    38   240     7  1067     7    47    59   402\n",
      "     4  3086  4832  6319    47  3244     7   392 17487  7836  4832  3216\n",
      "  2156  2350  2156   596 17487  3086  4832    38    95  3244     7    69\n",
      "     8    38   531  8109    38  4022    59    69  7836  4832  1464   350\n",
      "  2156    38  2528    79   197   192    10  6857  2156    53    79   938\n",
      "    75   182  1372    59    24  3086  4832   440  5170   479   479   479\n",
      "  7836  4832    38   216  2156    53    38   206    42    16  1473   479\n",
      "   264    18   584    79    18 16658  2156   101   961   198  2156    53\n",
      "    11    69   403    24   189    28  1528     2]\n",
      "[    0  3086  3244     7   392    59    69  6943   479   264   630    75\n",
      "   236     7   192    10  6857   479  7836  3649  1765    10 19902   479\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.16875)])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true Adam : She was telling me she doesn't feel like doing anything, she's bored all the time, she never feels happy. It sounds like a real, typical depression Adam : She also told me that she has trouble sleeping. I asked her to go out for a beer or anything basically, but she doesn't want to leave the flat Karen : Oh my, it sounds really serious. I don't what to tell you Adam : I was wondering how I can help her Karen : Honestly I don't know if we can help her, Adam. I suggested a specialist because these are very sensitive issues and I'm afraid we may unintentionally make it worse Adam : Yes, but she doesn't want to see a specialist. Basically, she doesn't want to see anyone Karen : Hm... I don't know\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Adam : I'm going to ask you a question, Karen, I'm wondering if you can help me with something, I think I need to talk to you about something. Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "W W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Scott : you know you're exactly fuckin the same. Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you're almost fuckin the exact same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file-gif>\n",
      "Generated summary length: torch.Size([1, 80])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O M O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O W O O C O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 80])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C C O O O O O O O O O O O C O O C O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "W W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mike : hey Ernest, I just got a call from my neighbor. Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
      "Generated summary length: torch.Size([1, 67])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O W W O O O O O\n",
      "Generated classification tag length: torch.Size([1, 67])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlotte : Hello Paula, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'nu' as in 'number'. Charlotte : And the stress on the second syllable? Or the first? Paula : 2nd Charlotte : Thank you dear. Paula : <file_other> Charlotte : Lovely to hear your voice!! Paula : : $ Paula : <file_other> Charlotte : : X\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Charlotte : Hello Paula, I'm so glad to hear your voice! Paula : <file_other> Charlotte : Thank you dear. Paula : : X. Charlotte : Hello Charlotte, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'na' as the first syllable? Or the first? Paula: 2nd Charlotte : And the stress on the second syllable : '\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O OB O O O O O N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdre, I'm been meaning to message you, had a favour to ask. Deirdre : Wondered if you had any thought about your Mum's 40th, we've got to do something special! Beth : How about a girls weekend, just mum, me, you and the girls, Kira will have to come back from Uni, of course. Deirdre : Sounds fab! Get your thinking cap on, it's only in 6 weeks! Bet she's dreading it, I remember doing that! Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdre : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies! What was the favour, darling? Beth : Oh, it was just that I fancied trying a bit of work experience in the salon, auntie. Deirdre : Well, I am looking for Saturday girls, are you sure about it? you could do well in the exams and go on to college or 6th form. Beth : I know, but it's not for me, auntie, I am doing all\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Beth : Hi, I'm Beth, I've been meaning to message you, had a favour to ask. Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdres, I haven't been in for a while, I just wanted to say hello. Deirdree : Hi I'm Deirdrea, I was just thinking about you, Beth. Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdle : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies!\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O OB C O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O OB C O O O O O O O O O O O O O C C O C O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24671  4832    38   437   164     7  1394    47    10   864\n",
      "  2156  7836  2156    38   437  8020   114    47    64   244   162    19\n",
      "   402  2156    38   206    38   240     7  1067     7    47    59   402\n",
      "     4  3086  4832  6319    47  3244     7   392 17487  7836  4832  3216\n",
      "  2156  2350  2156   596 17487  3086  4832    38    95  3244     7    69\n",
      "     8    38   531  8109    38  4022    59    69  7836  4832  1464   350\n",
      "  2156    38  2528    79   197   192    10  6857  2156    53    79   938\n",
      "    75   182  1372    59    24  3086  4832   440  5170   479   479   479\n",
      "  7836  4832    38   216  2156    53    38   206    42    16  1473   479\n",
      "   264    18   584    79    18 16658  2156   101   961   198  2156    53\n",
      "    11    69   403    24   189    28  1528     2]\n",
      "[    0  3086  3244     7   392    59    69  6943   479   264   630    75\n",
      "   236     7   192    10  6857   479  7836  3649  1765    10 19902   479\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.16875)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true Adam : She was telling me she doesn't feel like doing anything, she's bored all the time, she never feels happy. It sounds like a real, typical depression Adam : She also told me that she has trouble sleeping. I asked her to go out for a beer or anything basically, but she doesn't want to leave the flat Karen : Oh my, it sounds really serious. I don't what to tell you Adam : I was wondering how I can help her Karen : Honestly I don't know if we can help her, Adam. I suggested a specialist because these are very sensitive issues and I'm afraid we may unintentionally make it worse Adam : Yes, but she doesn't want to see a specialist. Basically, she doesn't want to see anyone Karen : Hm... I don't know\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Adam : I'm going to ask you a question, Karen, I'm wondering if you can help me with something, I think I need to talk to you about something. Adam : Have you talked to May? Karen : Yes, yesterday, why? Adam : I just talked to her and I must admit I worry about her Karen : Me too, I suggested she should see a specialist, but she wasn't very happy about it Adam : No wonder... Karen : I know, but I think this is serious. She's saying she's depressed, like everyone around, but in her case it may be true\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "W W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O C O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "W W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you know you're exactly fuckin the same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file_gif>\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Scott : you know you're exactly fuckin the same. Ethan : somethin for Scott <file_photo> Toby : haha, totally Marshall : pretty much sums it up Scott : you're almost fuckin the exact same Toby : oh we know honey bunny Marshall : we just enjoy making fun of YOU Ethan : xD Scott : oh fuck y'all Toby : <file-gif>\n",
      "Generated summary length: torch.Size([1, 80])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O M O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O W O O C O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 80])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C C O O W O O O O O O O O C O O C O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ben : Where are you? Emma : at the rare of the bus Ben : why? Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4. 15? Ben : sure Emma : thanks! Ben : sleep well Emma : I'll try\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to sleep now. Ben : Where are you? Emma : at the back of the bus Ben : why? Emma Emma : there are some free seats here Emma : so I can have a nap even Ben : good idea Emma : when are we going to arrive to NY? Ben : around 4. 30 PM Emma : if traffic is not crazy Ben : right, we will see Emma : could you come here and wake me up around 4 : 15? Ben: sure Emma : thanks! Ben : sleep well Emma : I'll try\n",
      "Generated summary length: torch.Size([1, 116])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "W W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 116])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mike : hey Ernest, I just got a call from my neighbor. Ernest : hey Mike, did you park your car on our street? Mike : no, took it into garage today Ernest : ok good Mike : why? Ernest : someone just crashed into a red honda looking just like yours Mike : lol lucky me\n",
      "Generated summary length: torch.Size([1, 67])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O C O O O C O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O W W O O O O O\n",
      "Generated classification tag length: torch.Size([1, 67])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Charlotte : Hello Paula, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'nu' as in 'number'. Charlotte : And the stress on the second syllable? Or the first? Paula : 2nd Charlotte : Thank you dear. Paula : <file_other> Charlotte : Lovely to hear your voice!! Paula : : $ Paula : <file_other> Charlotte : : X\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Charlotte : Hello Paula, I'm so glad to hear your voice! Paula : <file_other> Charlotte : Thank you dear. Paula : : X. Charlotte : Hello Charlotte, a funny question : how do you pronounce 'Natal lily', the name of the plant? It refers to the region of ZA and not to the word 'natal' as in 'his natal day', right? Paula : Hi Charlotte, 'nu tell', 'na' as the first syllable? Or the first? Paula: 2nd Charlotte : And the stress on the second syllable : '\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O OB O O O O O N O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdre, I'm been meaning to message you, had a favour to ask. Deirdre : Wondered if you had any thought about your Mum's 40th, we've got to do something special! Beth : How about a girls weekend, just mum, me, you and the girls, Kira will have to come back from Uni, of course. Deirdre : Sounds fab! Get your thinking cap on, it's only in 6 weeks! Bet she's dreading it, I remember doing that! Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdre : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies! What was the favour, darling? Beth : Oh, it was just that I fancied trying a bit of work experience in the salon, auntie. Deirdre : Well, I am looking for Saturday girls, are you sure about it? you could do well in the exams and go on to college or 6th form. Beth : I know, but it's not for me, auntie, I am doing all\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Beth : Hi, I'm Beth, I've been meaning to message you, had a favour to ask. Deirdre : Hi Beth, how are you love? Beth : Hi Auntie Deirdres, I haven't been in for a while, I just wanted to say hello. Deirdree : Hi I'm Deirdrea, I was just thinking about you, Beth. Beth : Oh yeah, we had a surprise party for you, you nearly had a heart attack! Deirdle : Well, it was a lovely surprise! Gosh, thats nearly 4 years ago now, time flies!\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O OB C O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O OB C O O O O O O O O O O O O O C C O C O O C O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24671  4832    38   437   164     7  1394    47    10   864\n",
      "  2156  7836  2156    38   437  8020   114    47    64   244   162    19\n",
      "   402  2156    38   206    38   240     7  1067     7    47    59   402\n",
      "     4  3086  4832  6319    47  3244     7   392 17487  7836  4832  3216\n",
      "  2156  2350  2156   596 17487  3086  4832    38    95  3244     7    69\n",
      "     8    38   531  8109    38  4022    59    69  7836  4832  1464   350\n",
      "  2156    38  2528    79   197   192    10  6857  2156    53    79   938\n",
      "    75   182  1372    59    24  3086  4832   440  5170   479   479   479\n",
      "  7836  4832    38   216  2156    53    38   206    42    16  1473   479\n",
      "   264    18   584    79    18 16658  2156   101   961   198  2156    53\n",
      "    11    69   403    24   189    28  1528     2]\n",
      "[    0  3086  3244     7   392    59    69  6943   479   264   630    75\n",
      "   236     7   192    10  6857   479  7836  3649  1765    10 19902   479\n",
      "     2     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.16875)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=15.311861289739609, metrics={'train_runtime': 304.434, 'train_samples_per_second': 1.314, 'train_steps_per_second': 1.314, 'total_flos': 216988411084800.0, 'train_loss': 15.311861289739609, 'epoch': 5.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6408768f-aea9-46da-b652-f4b9ac3be55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [' Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im at the train station Mary : cool, thanks']\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Mary : hey, im at the train station. Mary : hey, im kinda broke, lend me a few box Carter : okay, give me an hour, im in the train. Mary: cool, thanks\n",
      "Generated summary length: torch.Size([1, 45])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 45])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:41]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jesse : I have an idea that'll cheer u up! Melvin : What is it? Jesse : I was thinking about doing something 4 the less fortunate this year. Lee : Gr8 idea! Anything in mind? Maxine : So no presents 4 me? : ( Jesse : U'll get ur presents, no worries ; ) Maxine : Phew! Was getting a bit worried for a moment ; ) Melvin : Bt what do u have in store? Jesse : Well, have u heard about the Refuge? Lee : No. What's that? Melvin : That's the Christmas foundation to help women and children? Maxine : I think I've heard of them. So what about them? Jesse : That's right! They help women and children who escape from abuse. And every year they post wish lists of such ppl online and I thought that we could choose one and chip in. Melvin : That's a great idea! Lee : Count me in! Maxine : Me too. Jesse : Have a look at these 3 lists : <file_other> <file_other> <file_other> Lee : I think the second one would be the easiest to arrange. Maxine : Agree. Melvin : What about number 3? A\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Jesse : Hey Melvin, I'm here to see u and I'm sure u'll be happy to see me. Jesse : I have an idea that'll cheer u up! Melvin : What is it? Jesse : Well, I was thinking about doing something 4 the less fortunate this year. Lee : Gr8 idea! Anything in mind? Maxine : So no presents 4 me? : ( Jesse : U'll get ur presents, no worries ; ) Maxine: Phew! Was getting a bit worried for a moment ; ) Melvin : Bt what do u have in store? Jesse: Well, have u\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O W O O O W O O O O O O O O M O O O W O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O C O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Igor : Shit, I've got so much to do at work and I'm so demotivated. John : It's pretty irresponsible to give that much work to someone on their notice period. Igor : Yeah, exactly! Should I even care? John : It's up to you, but you know what they say... Igor : What do you mean? John : Well, they say how you end things shows how you really are... Igor : And now how you start, right? John : Gotcha! Igor : So what shall I do then? John : It's only two weeks left, so grit your teeth and do what you have to do. Igor : Easy to say, hard to perform. John : Come on, stop thinking, start doing! Igor : That's so typical of you! ; )\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "John : I'm going to be a little late for the party, but I'm not going to let that stop me from going. Igor : Shit, I've got so much to do at work and I'm so demotivated. John : It's pretty irresponsible to give that much work to someone on their notice period. Igor : Yeah, exactly! Should I even care? John : You know what they say... Igor: What do you mean? John: Well, they say how you end things shows how you really are..... Igor : And now how you start, right? John * Yes\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O M O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Ollie : Okay, Kelly! Ur up nxt! Kelly : Me? I don't wanna. Mickey : C'mon! Jessica : Yeah! What's yours? Kelly : Fine. It's a sculpture garden in Finnland. Ollie : What's scary about sculptures? Wait! Do they resemble vampires and stuff? Mickey : Nah, I'm sure they look rly nice. Kelly : It's not the sculptures, it's the amount of them and their faces! Jessica : Faces? What faces? Kelly : Well, they resemble ppl in different activities like hugging, training, doing sport and so on. But the faces are just morbid and there's like a hundred of them. All staring at you! Ollie : Another one? Mickey : Certainly! Jessica : Well, Ollie, ur turn! Ollie : Nagoro village in Japan! Mickey : Y? Ollie : Well, maybe it's not scary, but it similar to Kelly's place. It's just creepy as hell. Jessica : Bt y? Ollie : Imagine a village with ppl living in it. And in the same village u have these human-sized figures. And there's more of them than the ppl\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Jessica : I'm gonna go to the bathroom. Ollie : Okay, Kelly! Ur up nxt! Kelly : Me? I don't wanna. Mickey : C'mon! Jessica : Yeah! What's yours? Kelly : Fine. It's a sculpture garden in Finnland. OllIE : What's scary about sculptures? Wait! Do they resemble vampires and stuff? Mickey : Nah, I'm sure they look rly nice. Kelly : It's not the sculptures, it's the amount of them and their faces! Jessica: Faces? What faces? Kelly: Well, they resemble ppl in\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Clara : Hi, what you up to? Neela : Not much, chilling out. Clara : Just rewatching Dear White People on Netflix, love it! \\ue754 Neela : Oh yeah, heard of it, but not seen it yet? Any good? Clara : Well, yes! I just said it was, LOL. It's about a fictional Ivy League University and the students in one House of Residence. Neela : Why is it called Dear White People? Clara : That's the name of the radio show the main character, Sam, presents on college radio. Neela : Yeah, but why is it so good? Clara : Well, it's mainly stories from the perspective of black students there, which I find very interesting. The characters are strong and likeable too. Neela : I suppose it's rather different from the UK, then? Clara : It seems so, as there is a lot more racial awareness and discrimination there than here. It all kicks off when there is a Blackface party held by an elite group of white students, which gets out of hand. Neela : How's that? Clara : Well, obviously, the black students try to break it up and there's also an incident\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Hi, I'm Neela, I live in the UK, and I'm a student at the University of Cambridge. Clara : Hi, what you up to? Neela : Not much, chilling out. Clara : Just rewatching Dear White People on Netflix, love it!  Neela: Oh yeah, heard of it, but not seen it yet? Any good? Clara : Well, yes! I just said it was, LOL. It's about a fictional Ivy League University and the students in one House of Residence. Neela ( : Oh yeah, I've seen\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O N O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Anne : You were right, he was lying to me : / Irene : Oh no, what happened? Jane : who? that Mark guy? Anne : yeah, he told me he's 30, today I saw his passport - he's 40 Irene : You sure it's so important? Anne : he lied to me Irene\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Anne : I'm sorry, I'm so sorry. Anne : You were right, he was lying to me : / Irene : Oh no, what happened? Jane : who? that Mark guy? Anne : yeah, he told me he's 30, today I saw his passport - he's 40 Irene: Oh no, he lied to me Anne : he lied about his age Irene\n",
      "Generated summary length: torch.Size([1, 83])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O W O\n",
      "Generated classification tag length: torch.Size([1, 83])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it's all about experience Emma : But there are some rules and some typical texts right? Gloria : You can see some texts from previous years Gloria : <file_other> Emma : Wow that's very useful Emma : I have never seen this site Gloria : Yes it's very good Gloria : Actually it's good to read all the texts because you will see that some phrases repeat very often Emma : How much time do you have for all 4 parts? Gloria : 4 hours Emma : Is it enough? Gloria : Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4 hours and no breaks? Gloria : No breaks : / So it's really important to be really focused and try to write as fast as you can Gloria : And read it carefully and correct during the last hour Emma : I'm going to read everything from that website, it's great\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Emma : I'm going to read everything from that website, it's great. Gloria : This exam is a bit of a lottery in fact Gloria : You can't really get prepared, it will be really hard Emma : But there are some rules and some typical texts right? Gloria : Yes Emma : I have to read all the texts Emma : How much time do you have for all 4 parts? Gloria Gloria : 4 hours Emma : Is it enough? Gloria: Well it has to be Gloria : Would be perfect to have 2 more hours... But on the other hand it would be really exhausting Emma : 4\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yay! crap we need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : he did really. for no reason at all. Heather : whatever that make him happy Darlene : cool with me. we can shred some papers at the party Augustine : so much fun Heather : srsly guys, you mean we should really get office equipment??? Darlene : Walk, ask him if he really wnts it and if he yes then we get it Walker : i heard him say that. wasn ; t drunk. me neither. Darlene : but better ask him twice Walker : will do Augustine : 2moro ok? Darlene : and sure ask ab the party!\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Augustine : Hey guys, we need to talk about something. Augustine : Guys, remember it's Wharton's bday next week? Darlene : yay, a party! Heather : yacch, we should go to the party! Augustine : yah, we can go to a party. Darlne : ya, we also need to buy him a present Walker : he mentioned paper shredder once Augustine : wtf?!? Walker : did he really? Walker: he did really. for no reason at all. Heather : whatever that make him happy Darllene : cool with me\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O C O O O O O O O O O O O O O O O O O OB O O O O O O O O O O O O O O O O O O O O O O O C C O O O O O O O O O O O C O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Clara : Hi, what you up to? Neela : Not much, chilling out. Clara : Just rewatching Dear White People on Netflix, love it! \\ue754 Neela : Oh yeah, heard of it, but not seen it yet? Any good? Clara : Well, yes! I just said it was, LOL. It's about a fictional Ivy League University and the students in one House of Residence. Neela : Why is it called Dear White People? Clara : That's the name of the radio show the main character, Sam, presents on college radio. Neela : Yeah, but why is it so good? Clara : Well, it's mainly stories from the perspective of black students there, which I find very interesting. The characters are strong and likeable too. Neela : I suppose it's rather different from the UK, then? Clara : It seems so, as there is a lot more racial awareness and discrimination there than here. It all kicks off when there is a Blackface party held by an elite group of white students, which gets out of hand. Neela : How's that? Clara : Well, obviously, the black students try to break it up and there's also an incident\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Hi, I'm Neela, I live in the UK, and I'm a student at the University of Cambridge. Clara : Hi, what you up to? Neela : Not much, chilling out. Clara : Just rewatching Dear White People on Netflix, love it!  Neela: Oh yeah, heard of it, but not seen it yet? Any good? Clara : Well, yes! I just said it was, LOL. It's about a fictional Ivy League University and the students in one House of Residence. Neela ( : Oh yeah, I've seen\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O O O O O O N O O O O O O O O O O O O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "-----------------------------------------------------------------------------------------\n",
      "dialog:\n",
      " [\" Jesse : I have an idea that'll cheer u up! Melvin : What is it? Jesse : I was thinking about doing something 4 the less fortunate this year. Lee : Gr8 idea! Anything in mind? Maxine : So no presents 4 me? : ( Jesse : U'll get ur presents, no worries ; ) Maxine : Phew! Was getting a bit worried for a moment ; ) Melvin : Bt what do u have in store? Jesse : Well, have u heard about the Refuge? Lee : No. What's that? Melvin : That's the Christmas foundation to help women and children? Maxine : I think I've heard of them. So what about them? Jesse : That's right! They help women and children who escape from abuse. And every year they post wish lists of such ppl online and I thought that we could choose one and chip in. Melvin : That's a great idea! Lee : Count me in! Maxine : Me too. Jesse : Have a look at these 3 lists : <file_other> <file_other> <file_other> Lee : I think the second one would be the easiest to arrange. Maxine : Agree. Melvin : What about number 3? A\"]\n",
      "\n",
      "\n",
      "Generated Summaries:\n",
      "\n",
      "Jesse : Hey Melvin, I'm here to see u and I'm sure u'll be happy to see me. Jesse : I have an idea that'll cheer u up! Melvin : What is it? Jesse : Well, I was thinking about doing something 4 the less fortunate this year. Lee : Gr8 idea! Anything in mind? Maxine : So no presents 4 me? : ( Jesse : U'll get ur presents, no worries ; ) Maxine: Phew! Was getting a bit worried for a moment ; ) Melvin : Bt what do u have in store? Jesse: Well, have u\n",
      "Generated summary length: torch.Size([1, 128])\n",
      "\n",
      "Generated Classification Labels:\n",
      "\n",
      "O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O O W O O O O O W O O O W O O O O O O O O M O O O W O O C O O O O O O O O O O O O O O O O O O O O O O O O O O O C O\n",
      "Generated classification tag length: torch.Size([1, 128])\n",
      "In compute metrics\n",
      "[    2     0 24877  4832 17232  2156  4356    23     5  2341  1992     4\n",
      "  2708  4832 17232     6  4356 24282  2263  2156 15658   162    10   367\n",
      "  2233  5306  4832  8578  2156   492   162    41  1946  2156  4356    11\n",
      "     5  2341     4  2708    35  3035  2156  2446     2     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "[    0  5306    40 15658  2708    10  2233   479     2     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1     1     1     1     1\n",
      "     1     1     1     1     1     1     1     1]\n",
      "dict_items([('f1', 0.10234375)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 15.563984870910645,\n",
       " 'eval_f1': 0.1023,\n",
       " 'eval_runtime': 43.1704,\n",
       " 'eval_samples_per_second': 0.232,\n",
       " 'eval_steps_per_second': 0.232,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77cac4a5-1618-4e9b-b995-ea349bffdc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"hallucination-tagging-classifier-lmhead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86c1f586-c71d-4214-b575-c438704a6b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed580769-ba4a-4e66-9de1-9640eae77bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Dec  3 21:05:28 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3070 Ti   WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   41C    P8              15W / 310W |   7545MiB /  8192MiB |      6%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      3708      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A      6488    C+G   ...on\\119.0.2151.97\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A      8496    C+G   ...1.0_x64__cv1g1gvanyjgm\\WhatsApp.exe    N/A      |\n",
      "|    0   N/A  N/A      8500    C+G   ...2txyewy\\StartMenuExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9496    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe    N/A      |\n",
      "|    0   N/A  N/A      9596    C+G   C:\\Windows\\explorer.exe                   N/A      |\n",
      "|    0   N/A  N/A     10328    C+G   ...on\\119.0.2151.97\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     11540    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     11812      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     12732    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     13008    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     14228    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     14496    C+G   ...oogle\\Chrome\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     14892      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     15156    C+G   ...12.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     17444    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     18124    C+G   ...crosoft\\Edge\\Application\\msedge.exe    N/A      |\n",
      "|    0   N/A  N/A     18196      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "|    0   N/A  N/A     19052      C   ...\\anaconda3\\envs\\cap_proj\\python.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf4502d-31b9-4fff-86a7-ab01328abece",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
