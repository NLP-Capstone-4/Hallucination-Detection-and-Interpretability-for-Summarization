{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1dcee7c-0363-40b2-8a67-1cae64898c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import re, json\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_metric,Dataset,DatasetDict, load_dataset, Sequence, Value\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, BartForConditionalGeneration\n",
    "from transformers import AutoTokenizer, Trainer\n",
    "\n",
    "import evaluate\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "import os\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import List, Optional, Tuple, Union, Dict, Any\n",
    "from jointbart import myBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899f8323-f0cd-4591-a7fc-3d0d37aca400",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "_numpy_rng = np.random.default_rng(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.use_deterministic_algorithms(False)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7214fe4b-67d9-4614-8635-bb95efe58623",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e48ae316-d6f6-40fa-8bb3-378e03d1eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_iob(d):\n",
    "    for i in range(len(d)):\n",
    "        for j in range(len(d[i])):\n",
    "            if d[i][j] != 'O':\n",
    "                d[i][j] = 'B-' + d[i][j]\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "150af1a2-0059-44ef-ae69-7563650a6a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-large\"\n",
    "metric = evaluate.load(\"rouge\")\n",
    "f1_metric = evaluate.load(\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ae69bd-d3eb-4e28-b10a-3d30d3962e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 256\n",
    "max_target_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7781f554-4604-4ff1-b9b2-fc5a998bc09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of myBartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = myBartForConditionalGeneration.from_pretrained(model_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3f8cbea-454a-4bd9-b850-56ba4977aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if name == 'classifier.weight' or name == 'classifier.bias':\n",
    "        continue\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d9e4db0-eac9-42a8-94ad-7df8e88e2925",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('pvisnrt/mod_capstone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "376eef20-c4b0-44f4-8810-0622bc39cd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['source', 'summary_target', 'tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d5c2a7-e585-4a77-8b09-bd16b68d9e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afa59124-159c-442d-890f-9c0eb570f106",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'] = dataset['train'].cast_column(\"tags\", Sequence(Value(\"int32\")))\n",
    "dataset['validation'] = dataset['validation'].cast_column(\"tags\", Sequence(Value(\"int32\")))\n",
    "dataset['test'] = dataset['test'].cast_column(\"tags\", Sequence(Value(\"int32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "257738f7-0da2-4f96-8d3f-8a8500577bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'summary_target': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'tags': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e73fb4-5b3e-4ae7-b1d6-83f5835e386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    inputs = [doc for doc in examples['source']]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, is_split_into_words=True, return_tensors='pt', padding=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        tokenized_inputs = tokenizer(examples[\"summary_target\"], truncation=True, is_split_into_words=True, return_tensors='pt', padding=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)# Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            \n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    model_inputs['labels'] = tokenized_inputs['input_ids']\n",
    "\n",
    "    model_inputs[\"decoder_tags\"] = labels\n",
    "    \n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42855419-2f1d-4c20-bd68-ab82d2c6f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2462a5d2-6415-4342-811d-765089e25a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels', 'decoder_tags'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train'] = tokenized_datasets['train'].remove_columns(['source','summary_target', 'tags'])\n",
    "tokenized_datasets['validation'] = tokenized_datasets['validation'].remove_columns(['source','summary_target', 'tags'])\n",
    "tokenized_datasets['test'] = tokenized_datasets['test'].remove_columns(['source','summary_target', 'tags'])\n",
    "\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ee65ba8-4816-447e-8e2c-8767959e4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    def prediction_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "        prediction_loss_only: bool,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        Perform an evaluation step on `model` using `inputs`.\n",
    "        Subclass and override to inject custom behavior.\n",
    "        Args:\n",
    "            model (`nn.Module`):\n",
    "                The model to evaluate.\n",
    "            inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n",
    "                The inputs and targets of the model.\n",
    "                The dictionary will be unpacked before being fed to the model. Most models expect the targets under the\n",
    "                argument `labels`. Check your model's documentation for all accepted arguments.\n",
    "            prediction_loss_only (`bool`):\n",
    "                Whether or not to return the loss only.\n",
    "        Return:\n",
    "            Tuple[Optional[float], Optional[torch.Tensor], Optional[torch.Tensor]]: A tuple with the loss, logits and\n",
    "            labels (each being optional).\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.args.predict_with_generate or prediction_loss_only:\n",
    "            return super().prediction_step(\n",
    "                model, inputs, prediction_loss_only=prediction_loss_only, ignore_keys=ignore_keys\n",
    "            )\n",
    "\n",
    "        has_labels = \"decoder_tags\" in inputs\n",
    "        inputs = self._prepare_inputs(inputs)\n",
    "        \n",
    "        # print(\"prediction_step inputs: {}\".format(inputs.keys()))\n",
    "\n",
    "        # XXX: adapt synced_gpus for fairscale as well\n",
    "        gen_kwargs = self._gen_kwargs.copy()\n",
    "        if gen_kwargs.get(\"max_length\") is None and gen_kwargs.get(\"max_new_tokens\") is None:\n",
    "            gen_kwargs[\"max_length\"] = self.model.config.max_length\n",
    "        gen_kwargs[\"num_beams\"] = (\n",
    "            gen_kwargs[\"num_beams\"] if gen_kwargs.get(\"num_beams\") is not None else self.model.config.num_beams\n",
    "        )\n",
    "        # default_synced_gpus = True if is_deepspeed_zero3_enabled() else False\n",
    "        default_synced_gpus = False\n",
    "        gen_kwargs[\"synced_gpus\"] = (\n",
    "            gen_kwargs[\"synced_gpus\"] if gen_kwargs.get(\"synced_gpus\") is not None else default_synced_gpus\n",
    "        )\n",
    "\n",
    "        if \"attention_mask\" in inputs:\n",
    "            gen_kwargs[\"attention_mask\"] = inputs.get(\"attention_mask\", None)\n",
    "        if \"global_attention_mask\" in inputs:\n",
    "            gen_kwargs[\"global_attention_mask\"] = inputs.get(\"global_attention_mask\", None)\n",
    "\n",
    "        # prepare generation inputs\n",
    "        # some encoder-decoder models can have varying encoder's and thus\n",
    "        # varying model input names\n",
    "        if hasattr(self.model, \"encoder\") and self.model.encoder.main_input_name != self.model.main_input_name:\n",
    "            generation_inputs = inputs[self.model.encoder.main_input_name]\n",
    "        else:\n",
    "            generation_inputs = inputs[self.model.main_input_name]\n",
    "\n",
    "        tags = inputs[\"decoder_tags\"]\n",
    "        gen_kwargs.update({\"decoder_tags\": tags})\n",
    "        # print(f\"Gen kwargs: {gen_kwargs}\")\n",
    "        # print(f\"Gen inputs:{generation_inputs}\")\n",
    "        generated_tokens = self.model.generate(\n",
    "            generation_inputs,\n",
    "            **gen_kwargs,\n",
    "        )\n",
    "        # in case the batch is shorter than max length, the output should be padded\n",
    "        if gen_kwargs.get(\"max_length\") is not None and generated_tokens.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_length\"])\n",
    "        elif gen_kwargs.get(\"max_new_tokens\") is not None and generated_tokens.shape[-1] < (\n",
    "            gen_kwargs[\"max_new_tokens\"] + 1\n",
    "        ):\n",
    "            generated_tokens = self._pad_tensors_to_max_len(generated_tokens, gen_kwargs[\"max_new_tokens\"] + 1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if has_labels:\n",
    "                with self.compute_loss_context_manager():\n",
    "                    outputs = model(**inputs) # linear_logits as output\n",
    "                if self.label_smoother is not None:\n",
    "                    loss = self.label_smoother(outputs, inputs[\"decoder_tags\"]).mean().detach()\n",
    "                else:\n",
    "                    loss = (outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]).mean().detach()\n",
    "            else:\n",
    "                loss = None\n",
    "\n",
    "        if self.args.prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "\n",
    "        if has_labels:\n",
    "            labels = inputs[\"decoder_tags\"]\n",
    "            if gen_kwargs.get(\"max_length\") is not None and labels.shape[-1] < gen_kwargs[\"max_length\"]:\n",
    "                labels = self._pad_tensors_to_max_len(labels, gen_kwargs[\"max_length\"])\n",
    "            elif gen_kwargs.get(\"max_new_tokens\") is not None and labels.shape[-1] < (\n",
    "                gen_kwargs[\"max_new_tokens\"] + 1\n",
    "            ):\n",
    "                labels = self._pad_tensors_to_max_len(labels, (gen_kwargs[\"max_new_tokens\"] + 1))\n",
    "        else:\n",
    "            labels = None\n",
    "        # print(labels)\n",
    "\n",
    "        return (loss, generated_tokens, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da4e823b-e3d8-4b68-8a49-d327b130d1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"checkpoints/\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=4,\n",
    "    num_train_epochs=10,\n",
    "    predict_with_generate=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    fp16=True,\n",
    "    logging_steps=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    seed=42,\n",
    "    generation_max_length=max_target_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12bd51c9-2099-497d-8c34-945230f12dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0fd3626-cfd1-4b71-b11c-64792462b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "\n",
    "    print(\"In compute metrics\")\n",
    "\n",
    "    print(predictions[0])\n",
    "\n",
    "    print(labels[0])\n",
    "    \n",
    "    preds = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    # print(preds[0])\n",
    "    flattened_preds = [item for sublist in preds for item in sublist]\n",
    "    # decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # print(decoded_preds\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # print(labels[0])\n",
    "    flattened_labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "    result = f1_metric.compute(predictions=flattened_preds, references=flattened_labels, average='micro')\n",
    "    # decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # print(\"Decoded preds and labels\")\n",
    "\n",
    "    # print(decoded_preds)\n",
    "    # print(decoded_labels)\n",
    "    \n",
    "    # # Rouge expects a newline after each sentence\n",
    "    # decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    # decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    # result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    print(result.items())\n",
    "    #result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    # prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    # result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ab5cfb3f-6f29-40de-9f69-f421aac7e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MySeq2SeqTrainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df0508f1-b851-4c58-b532-df53b04932ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [800/800 01:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.855600</td>\n",
       "      <td>11.414522</td>\n",
       "      <td>0.835900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15.976700</td>\n",
       "      <td>11.153630</td>\n",
       "      <td>0.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>14.324600</td>\n",
       "      <td>10.966014</td>\n",
       "      <td>0.848400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>16.142900</td>\n",
       "      <td>10.833484</td>\n",
       "      <td>0.846100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>16.322900</td>\n",
       "      <td>10.737552</td>\n",
       "      <td>0.843800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>16.990700</td>\n",
       "      <td>10.672853</td>\n",
       "      <td>0.853900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>10.245300</td>\n",
       "      <td>10.630086</td>\n",
       "      <td>0.857000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>5.031100</td>\n",
       "      <td>10.602226</td>\n",
       "      <td>0.858600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>13.678500</td>\n",
       "      <td>10.586652</td>\n",
       "      <td>0.857800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13.473800</td>\n",
       "      <td>10.581438</td>\n",
       "      <td>0.860200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In compute metrics\n",
      "[2 0 7 6 7 6 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.8359375)])\n",
      "In compute metrics\n",
      "[2 0 6 6 7 6 6 6 4 6 6 1 5 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.85234375)])\n",
      "In compute metrics\n",
      "[2 0 6 6 5 6 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.8484375)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.84609375)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.84375)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.85390625)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 4 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.85703125)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 4 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.8585937500000002)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 4 6 6 7 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.8578125)])\n",
      "In compute metrics\n",
      "[2 0 6 6 6 5 6 6 4 6 6 7 6 6 3 6 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[-100    6    6    6    6    6    6    6    6    6    6 -100    6    6\n",
      "    6    6    6    6    6    6    6    6    6    6 -100 -100 -100 -100\n",
      " -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
      " -100 -100    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "dict_items([('f1', 0.86015625)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=14.565013017654419, metrics={'train_runtime': 95.2317, 'train_samples_per_second': 8.401, 'train_steps_per_second': 8.401, 'total_flos': 433432256102400.0, 'train_loss': 14.565013017654419, 'epoch': 10.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31adef8e-cf9b-4cf8-a8e7-ffe310b72912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Nov  4 11:20:19 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          Off | 00000000:A1:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              66W / 300W |  76604MiB / 81920MiB |     31%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2549      C   .../miniconda3/envs/nlp_env/bin/python    67946MiB |\n",
      "|    0   N/A  N/A      3528      C   .../miniconda3/envs/nlp_env/bin/python     8640MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
