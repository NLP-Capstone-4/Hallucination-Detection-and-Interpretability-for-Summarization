{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7378354-8f93-4ebe-9e9c-689d35f1f276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmazaher/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4614969d-8568-40ed-ab8a-a05b987cf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM = 500\n",
    "\n",
    "SEP_TOKEN = \" <SEP> \"\n",
    "EOS_TOKEN = \" <EOS>\"\n",
    "punctuations = ['!',',','.','?',\":\",\";\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e010dc-ae59-401f-8041-168b1d59bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_text(text):\n",
    "    curated_text = ''\n",
    "    if type(text) == str:\n",
    "        text = text.replace('\\n',' ')\n",
    "        for punctuation in punctuations:\n",
    "            text = text.replace(punctuation, ' ' + punctuation + ' ')\n",
    "        \n",
    "        curated_text = \" \".join(text.strip().split())\n",
    "    return curated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e013317-9d3d-4ce5-b69a-1b2b6fde3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source(row):\n",
    "    source = row['dialogue']\n",
    "    return source.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfe290d-3fdf-4434-8e22-469c60e4cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tgt_sum(row):\n",
    "    tgt_sum = row['summary']\n",
    "    return tgt_sum.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dafb472-b185-4f9d-a7b1-e399f5800686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags(row):    \n",
    "    return row['Annotations'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f8c977-2480-4e51-ae8b-01d29782d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(tokens):\n",
    "    return len(tokens)\n",
    "\n",
    "def map_tag_ids(tags):\n",
    "    return tagLabels.str2int(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a20794-6d00-44a7-a30f-0ab2189a5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stratified_into_train_val_test(df_input, frac_train=0.8, frac_val=0.1, frac_test=0.1):\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp = train_test_split(df_input, test_size=(1.0 - frac_train), random_state=42, shuffle=True)\n",
    "\n",
    "    \n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size = relative_frac_test, random_state=42, shuffle=True)\n",
    "    \n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "    \n",
    "    df_train.reset_index(drop=True, inplace = True)\n",
    "    df_val.reset_index(drop=True, inplace = True)\n",
    "    df_test.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a7f7d56f-e592-4fb8-9082-cbb945971350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('annotated_capstone_data.csv')\n",
    "\n",
    "df = df.iloc[FROM:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Dialogue</th>\n",
       "      <th>Reference Summary</th>\n",
       "      <th>Generated Summary</th>\n",
       "      <th>Annotations</th>\n",
       "      <th>Verified Tags</th>\n",
       "      <th>Missing Information</th>\n",
       "      <th>Redundant Information</th>\n",
       "      <th>Circumstance</th>\n",
       "      <th>Wrong Reference</th>\n",
       "      <th>Negation</th>\n",
       "      <th>Object</th>\n",
       "      <th>Tense</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Score</th>\n",
       "      <th>Model Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>100</td>\n",
       "      <td>Ethan: somethin for Scott &lt;file_photo&gt;\\nToby: ...</td>\n",
       "      <td>Ethan, Toby and Marshall are making fun of Sco...</td>\n",
       "      <td>Ethan and Marshall enjoy making fun of Scott.</td>\n",
       "      <td>O O O O O O O O O M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>BART-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>101</td>\n",
       "      <td>Ethan: somethin for Scott &lt;file_photo&gt;\\nToby: ...</td>\n",
       "      <td>Ethan, Toby and Marshall are making fun of Sco...</td>\n",
       "      <td>Ethan and Toby are making fun of Scott.</td>\n",
       "      <td>O O O O O O O O O M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "      <td>T5-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>102</td>\n",
       "      <td>Igor: Shit, I've got so much to do at work and...</td>\n",
       "      <td>Igor has a lot of work on his notice period an...</td>\n",
       "      <td>Igor has a lot of work to do at work. He's on ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>T5-Cons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>103</td>\n",
       "      <td>Igor: Shit, I've got so much to do at work and...</td>\n",
       "      <td>Igor has a lot of work on his notice period an...</td>\n",
       "      <td>Igor has only two weeks left before he has to ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Pegasus-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>104</td>\n",
       "      <td>Igor: Shit, I've got so much to do at work and...</td>\n",
       "      <td>Igor has a lot of work on his notice period an...</td>\n",
       "      <td>Igor is demotivated at work, because he has a ...</td>\n",
       "      <td>O O O O O O O O O O O O O O O O O O O O O O O M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Pegasus-Cons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>195</td>\n",
       "      <td>Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...</td>\n",
       "      <td>Jack and May will drink cocktails later.\\n</td>\n",
       "      <td>Jack and May are going to have some cocktails ...</td>\n",
       "      <td>O O O O O O O O O O O O O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Pegasus-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>196</td>\n",
       "      <td>Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...</td>\n",
       "      <td>Jack and May will drink cocktails later.\\n</td>\n",
       "      <td>May and Jack will have some cocktails later.</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T5-Cons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>197</td>\n",
       "      <td>Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...</td>\n",
       "      <td>Jack and May will drink cocktails later.\\n</td>\n",
       "      <td>May and Jack are going for cocktails later.</td>\n",
       "      <td>O O O O O O O O O O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>T5-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>198</td>\n",
       "      <td>Margaret: Honey, buy me some painkiller.\\nJack...</td>\n",
       "      <td>Margaret is suffering from a terrible headache...</td>\n",
       "      <td>Jack will buy Margaret some painkiller.</td>\n",
       "      <td>O C C O O O O M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>1.0</td>\n",
       "      <td>T5-Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>199</td>\n",
       "      <td>Margaret: Honey, buy me some painkiller.\\nJack...</td>\n",
       "      <td>Margaret is suffering from a terrible headache...</td>\n",
       "      <td>Margaret has a terrible headache. Jack will bu...</td>\n",
       "      <td>O O O O O O O C C O O O O M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>x</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pegasus-Cons</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                           Dialogue  \\\n",
       "500  100  Ethan: somethin for Scott <file_photo>\\nToby: ...   \n",
       "501  101  Ethan: somethin for Scott <file_photo>\\nToby: ...   \n",
       "502  102  Igor: Shit, I've got so much to do at work and...   \n",
       "503  103  Igor: Shit, I've got so much to do at work and...   \n",
       "504  104  Igor: Shit, I've got so much to do at work and...   \n",
       "..   ...                                                ...   \n",
       "595  195  Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...   \n",
       "596  196  Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...   \n",
       "597  197  Jack: Cocktails later?\\nMay: YES!!!\\nMay: You ...   \n",
       "598  198  Margaret: Honey, buy me some painkiller.\\nJack...   \n",
       "599  199  Margaret: Honey, buy me some painkiller.\\nJack...   \n",
       "\n",
       "                                     Reference Summary  \\\n",
       "500  Ethan, Toby and Marshall are making fun of Sco...   \n",
       "501  Ethan, Toby and Marshall are making fun of Sco...   \n",
       "502  Igor has a lot of work on his notice period an...   \n",
       "503  Igor has a lot of work on his notice period an...   \n",
       "504  Igor has a lot of work on his notice period an...   \n",
       "..                                                 ...   \n",
       "595         Jack and May will drink cocktails later.\\n   \n",
       "596         Jack and May will drink cocktails later.\\n   \n",
       "597         Jack and May will drink cocktails later.\\n   \n",
       "598  Margaret is suffering from a terrible headache...   \n",
       "599  Margaret is suffering from a terrible headache...   \n",
       "\n",
       "                                     Generated Summary  \\\n",
       "500      Ethan and Marshall enjoy making fun of Scott.   \n",
       "501            Ethan and Toby are making fun of Scott.   \n",
       "502  Igor has a lot of work to do at work. He's on ...   \n",
       "503  Igor has only two weeks left before he has to ...   \n",
       "504  Igor is demotivated at work, because he has a ...   \n",
       "..                                                 ...   \n",
       "595  Jack and May are going to have some cocktails ...   \n",
       "596       May and Jack will have some cocktails later.   \n",
       "597        May and Jack are going for cocktails later.   \n",
       "598            Jack will buy Margaret some painkiller.   \n",
       "599  Margaret has a terrible headache. Jack will bu...   \n",
       "\n",
       "                                           Annotations Verified Tags  \\\n",
       "500                                O O O O O O O O O M           NaN   \n",
       "501                                O O O O O O O O O M           NaN   \n",
       "502  O O O O O O O O O O O O O O O O O O O O O O O ...           NaN   \n",
       "503  O O O O O O O O O O O O O O O O O O O O O O O ...           NaN   \n",
       "504    O O O O O O O O O O O O O O O O O O O O O O O M           NaN   \n",
       "..                                                 ...           ...   \n",
       "595                          O O O O O O O O O O O O O           NaN   \n",
       "596                                O O O O O O O O O O           NaN   \n",
       "597                                O O O O O O O O O O           NaN   \n",
       "598                                    O C C O O O O M           NaN   \n",
       "599                        O O O O O O O C C O O O O M           NaN   \n",
       "\n",
       "    Missing Information Redundant Information Circumstance Wrong Reference  \\\n",
       "500                   x                   NaN          NaN             NaN   \n",
       "501                   x                   NaN          NaN             NaN   \n",
       "502                   x                     x          NaN             NaN   \n",
       "503                   x                   NaN          NaN             NaN   \n",
       "504                   x                   NaN          NaN             NaN   \n",
       "..                  ...                   ...          ...             ...   \n",
       "595                 NaN                   NaN          NaN             NaN   \n",
       "596                 NaN                   NaN          NaN             NaN   \n",
       "597                 NaN                   NaN          NaN             NaN   \n",
       "598                 NaN                   NaN          NaN             NaN   \n",
       "599                 NaN                   NaN          NaN             NaN   \n",
       "\n",
       "    Negation Object Tense Modality  Score        Model Name  \n",
       "500      NaN    NaN   NaN      NaN    7.0     BART-Baseline  \n",
       "501      NaN    NaN   NaN      NaN    8.0       T5-Baseline  \n",
       "502      NaN    NaN   NaN      NaN    7.0           T5-Cons  \n",
       "503      NaN      x   NaN      NaN    7.0  Pegasus-Baseline  \n",
       "504      NaN    NaN   NaN      NaN    7.0      Pegasus-Cons  \n",
       "..       ...    ...   ...      ...    ...               ...  \n",
       "595      NaN    NaN   NaN      NaN   10.0  Pegasus-Baseline  \n",
       "596      NaN    NaN   NaN      NaN   10.0           T5-Cons  \n",
       "597      NaN    NaN   NaN      NaN   10.0       T5-Baseline  \n",
       "598      NaN    NaN   NaN        x    1.0       T5-Baseline  \n",
       "599      NaN    NaN   NaN        x    5.0      Pegasus-Cons  \n",
       "\n",
       "[100 rows x 16 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14732/14732 [00:05<00:00, 2489.32it/s]\n",
      "100%|██████████| 819/819 [00:00<00:00, 2192.50it/s]\n",
      "100%|██████████| 818/818 [00:00<00:00, 2133.49it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "ds = load_dataset(\"samsum\")\n",
    "\n",
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['dialogue', 'summary', 'gold_tags'])\n",
    "\n",
    "# add all the data to the dataframe\n",
    "for split in ds.keys():\n",
    "    for i in tqdm(range(len(ds[split]))):\n",
    "        new_row = {'dialogue': ds[split][i]['dialogue'], 'summary': ds[split][i]['summary'], 'gold_tags': ''}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720e4cbd-fbcc-48f4-be19-49845985a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dialogue'] = df['dialogue'].apply(curate_text)\n",
    "df['summary'] = df['summary'].apply(curate_text)\n",
    "# df['Annotations'] = df['Annotations'].apply(curate_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7169bb-d902-4af4-a5f1-b570f8c340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df.apply(create_source, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7dee49e-8497-45a7-8746-fdf81266f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_target'] = df.apply(create_tgt_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "829dcee4-39ea-41ae-8451-c34fd244ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tags'] = df.apply(create_tags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bddfc0a-d751-4448-bd09-c192a7681273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tag_labels = np.unique(df['tags'].sum()).tolist()\n",
    "# tagLabels = datasets.ClassLabel(num_classes=len(tag_labels), names=tag_labels)\n",
    "\n",
    "# df['tag_ids'] = df['tags'].apply(map_tag_ids)\n",
    "df['gold_tags'] = df['summary_target'].apply(lambda x: [6] * len(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d0bf720-4e55-422f-87af-d21f267ef268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'summary_target': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'gold_tags': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "ds_features = datasets.Features({\n",
    "    'source': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None), \n",
    "    'summary_target': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None),\n",
    "    # 'tags': datasets.Sequence(feature=tagLabels, length=-1, id=None),\n",
    "    'gold_tags': datasets.Sequence(feature=datasets.Value(dtype='int32', id=None), length=-1, id=None),\n",
    "})\n",
    "print(ds_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c468ec2-89b3-48c9-ace0-23d09d220040",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame()\n",
    "dataset_df['source'] = df['source']\n",
    "dataset_df['summary_target'] = df['summary_target']\n",
    "# dataset_df['tags'] = df['tag_ids']\n",
    "dataset_df['gold_tags'] = df['gold_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc3a72b-7417-420a-8da3-c62efde33d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_df['summary_target'][500]) == len(dataset_df['tags'][500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary_target</th>\n",
       "      <th>gold_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Amanda, :, I, baked, cookies, ., Do, you, wan...</td>\n",
       "      <td>[Amanda, baked, cookies, and, will, bring, Jer...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Olivia, :, Who, are, you, voting, for, in, th...</td>\n",
       "      <td>[Olivia, and, Olivier, are, voting, for, liber...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Tim, :, Hi, ,, what's, up, ?, Kim, :, Bad, mo...</td>\n",
       "      <td>[Kim, may, try, the, pomodoro, technique, reco...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Edward, :, Rachel, ,, I, think, I'm, in, ove,...</td>\n",
       "      <td>[Edward, thinks, he, is, in, love, with, Bella...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Sam, :, hey, overheard, rick, say, something,...</td>\n",
       "      <td>[Sam, is, confused, ,, because, he, overheard,...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>[Carla, :, I've, got, it, ., ., ., Diego, :, w...</td>\n",
       "      <td>[Carla's, date, for, graduation, is, on, June,...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16365</th>\n",
       "      <td>[Gita, :, Hello, ,, this, is, Beti's, Mum, Git...</td>\n",
       "      <td>[Bev, is, going, on, the, school, trip, with, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>[Julia, :, Greg, just, texted, me, Robert, :, ...</td>\n",
       "      <td>[Greg, cheated, on, Julia, ., He, apologises, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16367</th>\n",
       "      <td>[Marry, :, I, broke, my, nail, ;, (, Tina, :, ...</td>\n",
       "      <td>[Marry, broke, her, nail, and, has, a, party, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16368</th>\n",
       "      <td>[Paige, :, I, asked, them, to, wait, and, send...</td>\n",
       "      <td>[Paige, wants, to, have, the, declaration, sen...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16369 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      [Amanda, :, I, baked, cookies, ., Do, you, wan...   \n",
       "1      [Olivia, :, Who, are, you, voting, for, in, th...   \n",
       "2      [Tim, :, Hi, ,, what's, up, ?, Kim, :, Bad, mo...   \n",
       "3      [Edward, :, Rachel, ,, I, think, I'm, in, ove,...   \n",
       "4      [Sam, :, hey, overheard, rick, say, something,...   \n",
       "...                                                  ...   \n",
       "16364  [Carla, :, I've, got, it, ., ., ., Diego, :, w...   \n",
       "16365  [Gita, :, Hello, ,, this, is, Beti's, Mum, Git...   \n",
       "16366  [Julia, :, Greg, just, texted, me, Robert, :, ...   \n",
       "16367  [Marry, :, I, broke, my, nail, ;, (, Tina, :, ...   \n",
       "16368  [Paige, :, I, asked, them, to, wait, and, send...   \n",
       "\n",
       "                                          summary_target  \\\n",
       "0      [Amanda, baked, cookies, and, will, bring, Jer...   \n",
       "1      [Olivia, and, Olivier, are, voting, for, liber...   \n",
       "2      [Kim, may, try, the, pomodoro, technique, reco...   \n",
       "3      [Edward, thinks, he, is, in, love, with, Bella...   \n",
       "4      [Sam, is, confused, ,, because, he, overheard,...   \n",
       "...                                                  ...   \n",
       "16364  [Carla's, date, for, graduation, is, on, June,...   \n",
       "16365  [Bev, is, going, on, the, school, trip, with, ...   \n",
       "16366  [Greg, cheated, on, Julia, ., He, apologises, ...   \n",
       "16367  [Marry, broke, her, nail, and, has, a, party, ...   \n",
       "16368  [Paige, wants, to, have, the, declaration, sen...   \n",
       "\n",
       "                                               gold_tags  \n",
       "0                         [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "1                      [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "2          [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "3      [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "4      [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "...                                                  ...  \n",
       "16364   [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "16365  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "16366  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "16367  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "16368  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "\n",
       "[16369 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e947acca-6967-4963-a5be-d6149d633b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_stratified_into_train_val_test(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ba889613-5ad4-4dcb-962f-dad7ff90de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(df_train, features=ds_features, split='train')\n",
    "val_ds = datasets.Dataset.from_pandas(df_val, features=ds_features, split='validation')\n",
    "test_ds = datasets.Dataset.from_pandas(df_test, features=ds_features, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "19bb3ac9-0c82-46c7-8288-74487b742c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:00<00:00, 68.52ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 59.88ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "Downloading metadata: 100%|██████████| 536/536 [00:00<00:00, 3.49MB/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 2/2 [00:00<00:00, 61.64ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.06it/s]\n",
      "Downloading metadata: 100%|██████████| 653/653 [00:00<00:00, 5.53MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token = \"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\"\n",
    "dataset_name = 'samsum_dataset'\n",
    "train_ds.push_to_hub(f'pvisnrt/{dataset_name}', token=token)\n",
    "val_ds.push_to_hub(f'pvisnrt/{dataset_name}', token=token)\n",
    "test_ds.push_to_hub(f'pvisnrt/{dataset_name}', token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samsum adding Ground Truth (O) column - old version (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14732/14732 [00:05<00:00, 2548.57it/s]\n",
      "100%|██████████| 819/819 [00:00<00:00, 2241.32it/s]\n",
      "100%|██████████| 818/818 [00:00<00:00, 2221.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "ds = load_dataset(\"samsum\")\n",
    "\n",
    "# empty dataframe\n",
    "df = pd.DataFrame(columns=['dialogue', 'summary', 'gold_tags'])\n",
    "\n",
    "# add all the data to the dataframe\n",
    "for split in ds.keys():\n",
    "    for i in tqdm(range(len(ds[split]))):\n",
    "        new_row = {'dialogue': ds[split][i]['dialogue'], 'summary': ds[split][i]['summary'], 'gold_tags': ''}\n",
    "        df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>gold_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amanda: I baked  cookies. Do you want some?\\r\\...</td>\n",
       "      <td>Amanda baked cookies and will bring Jerry some...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Olivia: Who are you voting for in this electio...</td>\n",
       "      <td>Olivia and Olivier are voting for liberals in ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...</td>\n",
       "      <td>Kim may try the pomodoro technique recommended...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Edward: Rachel, I think I'm in ove with Bella....</td>\n",
       "      <td>Edward thinks he is in love with Bella. Rachel...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sam: hey  overheard rick say something\\r\\nSam:...</td>\n",
       "      <td>Sam is confused, because he overheard Rick com...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...</td>\n",
       "      <td>Carla's date for graduation is on June 4th. Di...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16365</th>\n",
       "      <td>Gita: Hello, this is Beti's Mum Gita, I wanted...</td>\n",
       "      <td>Bev is going on the school trip with her son. ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>Julia: Greg just texted me\\r\\nRobert: ugh, del...</td>\n",
       "      <td>Greg cheated on Julia. He apologises to her. R...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16367</th>\n",
       "      <td>Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...</td>\n",
       "      <td>Marry broke her nail and has a party tomorrow....</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16368</th>\n",
       "      <td>Paige: I asked them to wait and send the decla...</td>\n",
       "      <td>Paige wants to have the declaration sent later...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16369 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dialogue  \\\n",
       "0      Amanda: I baked  cookies. Do you want some?\\r\\...   \n",
       "1      Olivia: Who are you voting for in this electio...   \n",
       "2      Tim: Hi, what's up?\\r\\nKim: Bad mood tbh, I wa...   \n",
       "3      Edward: Rachel, I think I'm in ove with Bella....   \n",
       "4      Sam: hey  overheard rick say something\\r\\nSam:...   \n",
       "...                                                  ...   \n",
       "16364  Carla: I've got it...\\r\\nDiego: what?\\r\\nCarla...   \n",
       "16365  Gita: Hello, this is Beti's Mum Gita, I wanted...   \n",
       "16366  Julia: Greg just texted me\\r\\nRobert: ugh, del...   \n",
       "16367  Marry: I broke my nail ;(\\r\\nTina: oh, no!\\r\\n...   \n",
       "16368  Paige: I asked them to wait and send the decla...   \n",
       "\n",
       "                                                 summary gold_tags  \n",
       "0      Amanda baked cookies and will bring Jerry some...            \n",
       "1      Olivia and Olivier are voting for liberals in ...            \n",
       "2      Kim may try the pomodoro technique recommended...            \n",
       "3      Edward thinks he is in love with Bella. Rachel...            \n",
       "4      Sam is confused, because he overheard Rick com...            \n",
       "...                                                  ...       ...  \n",
       "16364  Carla's date for graduation is on June 4th. Di...            \n",
       "16365  Bev is going on the school trip with her son. ...            \n",
       "16366  Greg cheated on Julia. He apologises to her. R...            \n",
       "16367  Marry broke her nail and has a party tomorrow....            \n",
       "16368  Paige wants to have the declaration sent later...            \n",
       "\n",
       "[16369 rows x 3 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dialogue'] = df['dialogue'].apply(curate_text)\n",
    "df['summary'] = df['summary'].apply(curate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Dialogue'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Dialogue'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnlp2/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(create_source, axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp2/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39msummary\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(create_tgt_sum, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10025\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10027\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m  10028\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  10029\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10035\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m  10036\u001b[0m )\n\u001b[0;32m> 10037\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/apply.py:837\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    835\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 837\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/apply.py:963\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 963\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    965\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    966\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/apply.py:979\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    977\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    978\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 979\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(v, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    980\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    981\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    982\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    983\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32m/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb Cell 28\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp2/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_source\u001b[39m(row):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnlp2/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     source \u001b[39m=\u001b[39m row[\u001b[39m'\u001b[39;49m\u001b[39mDialogue\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnlp2/home/pmazaher/Capstone-4/Approach2/data_prep/prepare_hg_dataset.ipynb#X55sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m source\u001b[39m.\u001b[39msplit()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Dialogue'"
     ]
    }
   ],
   "source": [
    "df['source'] = df.apply(create_source, axis = 1)\n",
    "df['summary'] = df.apply(create_tgt_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to tokenize summary and create 'O' sequence\n",
    "def create_o_sequence(summary):\n",
    "    tokens = summary.split()  # Simple tokenization by splitting on whitespace\n",
    "    o_sequence = [\"O\"] * len(tokens)\n",
    "    return ' '.join(o_sequence)\n",
    "\n",
    "# Iterate through each split and modify the dataset\n",
    "for split in samsum_dataset.keys():\n",
    "    # Add a new column with 'O' sequence for each summary\n",
    "    samsum_dataset[split] = samsum_dataset[split].map(lambda x: {\"gold_tags\": create_o_sequence(x[\"summary\"])})\n",
    "\n",
    "\n",
    "\n",
    "#  push it to the hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 15/15 [00:00<00:00, 305.50ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:01<00:00,  1.78s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 320.74ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.43it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 400.22ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "token = \"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\"\n",
    "samsum_dataset.push_to_hub(\"pvisnrt/samsum\", token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13818513',\n",
       " 'dialogue': \"Amanda: I baked  cookies. Do you want some?\\r\\nJerry: Sure!\\r\\nAmanda: I'll bring you tomorrow :-)\",\n",
       " 'summary': 'Amanda baked cookies and will bring Jerry some tomorrow.',\n",
       " 'gold_tags': 'O O O O O O O O O'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsum_dataset['train'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
