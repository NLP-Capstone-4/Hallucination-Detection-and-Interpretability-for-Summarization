{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7378354-8f93-4ebe-9e9c-689d35f1f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4614969d-8568-40ed-ab8a-a05b987cf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM = 500\n",
    "\n",
    "SEP_TOKEN = \" <SEP> \"\n",
    "EOS_TOKEN = \" <EOS>\"\n",
    "punctuations = ['!',',','.','?',\":\",\";\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ba55a3-2d38-4b13-b8ea-b2c68fbc13f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'C': 3,\n",
    "    'M':4,\n",
    "    'N':5,\n",
    "    'O':6,\n",
    "    'OB':7,\n",
    "    'W':8,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3e010dc-ae59-401f-8041-168b1d59bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_text(text):\n",
    "    curated_text = ''\n",
    "    if type(text) == str:\n",
    "        text = text.replace('\\n',' ')\n",
    "        for punctuation in punctuations:\n",
    "            text = text.replace(punctuation, ' ' + punctuation + ' ')\n",
    "        \n",
    "        curated_text = \" \".join(text.strip().split())\n",
    "    return curated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e013317-9d3d-4ce5-b69a-1b2b6fde3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source(row):\n",
    "    source = row['Dialogue']\n",
    "    return source.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bfe290d-3fdf-4434-8e22-469c60e4cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tgt_sum(row):\n",
    "    tgt_sum = row['Generated Summary']\n",
    "    return tgt_sum.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dafb472-b185-4f9d-a7b1-e399f5800686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags(row): \n",
    "    return row['Annotations'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f8c977-2480-4e51-ae8b-01d29782d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(tokens):\n",
    "    return len(tokens)\n",
    "\n",
    "def map_tag_ids(tags):\n",
    "    return [mapping[tag] for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a20794-6d00-44a7-a30f-0ab2189a5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stratified_into_train_val_test(df_input, frac_train=0.8, frac_val=0.1, frac_test=0.1):\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp = train_test_split(df_input, test_size=(1.0 - frac_train), random_state=42, shuffle=True)\n",
    "\n",
    "    \n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size = relative_frac_test, random_state=42, shuffle=True)\n",
    "    \n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "    \n",
    "    df_train.reset_index(drop=True, inplace = True)\n",
    "    df_val.reset_index(drop=True, inplace = True)\n",
    "    df_test.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f7d56f-e592-4fb8-9082-cbb945971350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('annotated_capstone_data.csv')\n",
    "\n",
    "df = df.iloc[FROM:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "720e4cbd-fbcc-48f4-be19-49845985a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dialogue'] = df['Dialogue'].apply(curate_text)\n",
    "df['Generated Summary'] = df['Generated Summary'].apply(curate_text)\n",
    "df['Annotations'] = df['Annotations'].apply(curate_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a5ecd4-5061-40b4-b0c4-7c9245925fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500                                  O O O O O O O O O M\n",
       "501                                  O O O O O O O O O M\n",
       "502    O O O O O O O O O O O O O O O O O O O O O O O ...\n",
       "503    O O O O O O O O O O O O O O O O O O O O O O O ...\n",
       "504      O O O O O O O O O O O O O O O O O O O O O O O M\n",
       "                             ...                        \n",
       "595                            O O O O O O O O O O O O O\n",
       "596                                  O O O O O O O O O O\n",
       "597                                  O O O O O O O O O O\n",
       "598                                      O C C O O O O M\n",
       "599                          O O O O O O O C C O O O O M\n",
       "Name: Annotations, Length: 100, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Annotations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b7169bb-d902-4af4-a5f1-b570f8c340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df.apply(create_source, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7dee49e-8497-45a7-8746-fdf81266f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_target'] = df.apply(create_tgt_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "829dcee4-39ea-41ae-8451-c34fd244ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df.apply(create_tags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bddfc0a-d751-4448-bd09-c192a7681273",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_labels = np.unique(df['tags'].sum()).tolist()\n",
    "tagLabels = datasets.Sequence(feature=datasets.Value(dtype='int64'))\n",
    "\n",
    "df['tag_ids'] = df['tags'].apply(map_tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "270c0b26-0900-42ad-a59d-88d7c6d57ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500                       [6, 6, 6, 6, 6, 6, 6, 6, 6, 4]\n",
       "501                       [6, 6, 6, 6, 6, 6, 6, 6, 6, 4]\n",
       "502    [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
       "503    [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
       "504    [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
       "                             ...                        \n",
       "595              [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
       "596                       [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
       "597                       [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]\n",
       "598                             [6, 3, 3, 6, 6, 6, 6, 4]\n",
       "599           [6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 4]\n",
       "Name: tag_ids, Length: 100, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tag_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d0bf720-4e55-422f-87af-d21f267ef268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'summary_target': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'tags': Sequence(feature=Sequence(feature=Value(dtype='int64', id=None), length=-1, id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "ds_features = datasets.Features({\n",
    "    'source': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None), \n",
    "    'summary_target': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None),\n",
    "    'tags': datasets.Sequence(feature=tagLabels, length=-1, id=None, )\n",
    "})\n",
    "print(ds_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5c468ec2-89b3-48c9-ace0-23d09d220040",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame()\n",
    "dataset_df['source'] = df['source']\n",
    "dataset_df['summary_target'] = df['summary_target']\n",
    "dataset_df['tags'] = df['tag_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "98a1a2e0-acd8-4006-ab9f-131e2511a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary_target</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>[Ethan, :, somethin, for, Scott, &lt;file_photo&gt;,...</td>\n",
       "      <td>[Ethan, and, Marshall, enjoy, making, fun, of,...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>[Ethan, :, somethin, for, Scott, &lt;file_photo&gt;,...</td>\n",
       "      <td>[Ethan, and, Toby, are, making, fun, of, Scott...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, has, a, lot, of, work, to, do, at, work...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, has, only, two, weeks, left, before, he...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, is, demotivated, at, work, ,, because, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[Jack, and, May, are, going, to, have, some, c...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[May, and, Jack, will, have, some, cocktails, ...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[May, and, Jack, are, going, for, cocktails, l...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 6, 6, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[Margaret, :, Honey, ,, buy, me, some, painkil...</td>\n",
       "      <td>[Jack, will, buy, Margaret, some, painkiller, .]</td>\n",
       "      <td>[6, 3, 3, 6, 6, 6, 6, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[Margaret, :, Honey, ,, buy, me, some, painkil...</td>\n",
       "      <td>[Margaret, has, a, terrible, headache, ., Jack...</td>\n",
       "      <td>[6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "500  [Ethan, :, somethin, for, Scott, <file_photo>,...   \n",
       "501  [Ethan, :, somethin, for, Scott, <file_photo>,...   \n",
       "502  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "503  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "504  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "..                                                 ...   \n",
       "595  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "596  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "597  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "598  [Margaret, :, Honey, ,, buy, me, some, painkil...   \n",
       "599  [Margaret, :, Honey, ,, buy, me, some, painkil...   \n",
       "\n",
       "                                        summary_target  \\\n",
       "500  [Ethan, and, Marshall, enjoy, making, fun, of,...   \n",
       "501  [Ethan, and, Toby, are, making, fun, of, Scott...   \n",
       "502  [Igor, has, a, lot, of, work, to, do, at, work...   \n",
       "503  [Igor, has, only, two, weeks, left, before, he...   \n",
       "504  [Igor, is, demotivated, at, work, ,, because, ...   \n",
       "..                                                 ...   \n",
       "595  [Jack, and, May, are, going, to, have, some, c...   \n",
       "596  [May, and, Jack, will, have, some, cocktails, ...   \n",
       "597  [May, and, Jack, are, going, for, cocktails, l...   \n",
       "598   [Jack, will, buy, Margaret, some, painkiller, .]   \n",
       "599  [Margaret, has, a, terrible, headache, ., Jack...   \n",
       "\n",
       "                                                  tags  \n",
       "500                     [6, 6, 6, 6, 6, 6, 6, 6, 6, 4]  \n",
       "501                     [6, 6, 6, 6, 6, 6, 6, 6, 6, 4]  \n",
       "502  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "503  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "504  [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...  \n",
       "..                                                 ...  \n",
       "595            [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "596                     [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "597                     [6, 6, 6, 6, 6, 6, 6, 6, 6, 6]  \n",
       "598                           [6, 3, 3, 6, 6, 6, 6, 4]  \n",
       "599         [6, 6, 6, 6, 6, 6, 6, 3, 3, 6, 6, 6, 6, 4]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9dc3a72b-7417-420a-8da3-c62efde33d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_df['summary_target'][500]) == len(dataset_df['tags'][500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e947acca-6967-4963-a5be-d6149d633b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_stratified_into_train_val_test(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba889613-5ad4-4dcb-962f-dad7ff90de29",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Couldn't cast array of type\nint64\nto\nSequence(feature=Value(dtype='int64', id=None), length=-1, id=None)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m val_ds \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_pandas(df_val, features\u001b[38;5;241m=\u001b[39mds_features, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_ds \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_pandas(df_test, features\u001b[38;5;241m=\u001b[39mds_features, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/arrow_dataset.py:867\u001b[0m, in \u001b[0;36mDataset.from_pandas\u001b[0;34m(cls, df, features, info, split, preserve_index)\u001b[0m\n\u001b[1;32m    860\u001b[0m table \u001b[38;5;241m=\u001b[39m InMemoryTable\u001b[38;5;241m.\u001b[39mfrom_pandas(\n\u001b[1;32m    861\u001b[0m     df\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m    862\u001b[0m     preserve_index\u001b[38;5;241m=\u001b[39mpreserve_index,\n\u001b[1;32m    863\u001b[0m )\n\u001b[1;32m    864\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;66;03m# more expensive cast than InMemoryTable.from_pandas(..., schema=features.arrow_schema)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;66;03m# needed to support the str to Audio conversion for instance\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m     table \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrow_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(table, info\u001b[38;5;241m=\u001b[39minfo, split\u001b[38;5;241m=\u001b[39msplit)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:901\u001b[0m, in \u001b[0;36mInMemoryTable.cast\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcast\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    889\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m    Cast table values to another schema.\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m        `datasets.table.Table`\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InMemoryTable(\u001b[43mtable_cast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:2328\u001b[0m, in \u001b[0;36mtable_cast\u001b[0;34m(table, schema)\u001b[0m\n\u001b[1;32m   2314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Improved version of `pa.Table.cast`.\u001b[39;00m\n\u001b[1;32m   2315\u001b[0m \n\u001b[1;32m   2316\u001b[0m \u001b[38;5;124;03mIt supports casting to feature types stored in the schema metadata.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2325\u001b[0m \u001b[38;5;124;03m    table (`pyarrow.Table`): the casted table\u001b[39;00m\n\u001b[1;32m   2326\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m!=\u001b[39m schema:\n\u001b[0;32m-> 2328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast_table_to_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m table\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m!=\u001b[39m schema\u001b[38;5;241m.\u001b[39mmetadata:\n\u001b[1;32m   2330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m table\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(schema\u001b[38;5;241m.\u001b[39mmetadata)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:2287\u001b[0m, in \u001b[0;36mcast_table_to_schema\u001b[0;34m(table, schema)\u001b[0m\n\u001b[1;32m   2285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumn_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28msorted\u001b[39m(features):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2287\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [cast_array_to_feature(table[name], feature) \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:2287\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(table\u001b[38;5;241m.\u001b[39mcolumn_names) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28msorted\u001b[39m(features):\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfeatures\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mbecause column names don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2287\u001b[0m arrays \u001b[38;5;241m=\u001b[39m [\u001b[43mcast_array_to_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m name, feature \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mTable\u001b[38;5;241m.\u001b[39mfrom_arrays(arrays, schema\u001b[38;5;241m=\u001b[39mschema)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:1831\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, pa\u001b[38;5;241m.\u001b[39mChunkedArray):\n\u001b[0;32m-> 1831\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1833\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:1831\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1829\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, pa\u001b[38;5;241m.\u001b[39mChunkedArray):\n\u001b[0;32m-> 1831\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1833\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(array, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:2095\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2093\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mFixedSizeListArray\u001b[38;5;241m.\u001b[39mfrom_arrays(_c(array\u001b[38;5;241m.\u001b[39mvalues, feature\u001b[38;5;241m.\u001b[39mfeature), feature\u001b[38;5;241m.\u001b[39mlength)\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2095\u001b[0m     casted_values \u001b[38;5;241m=\u001b[39m \u001b[43m_c\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m casted_values\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m array\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtype:\n\u001b[1;32m   2097\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m array\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:1833\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mchunked_array([func(chunk, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m array\u001b[38;5;241m.\u001b[39mchunks])\n\u001b[1;32m   1832\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp_env/lib/python3.9/site-packages/datasets/table.py:2144\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feature, (Sequence, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m   2143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array_cast(array, feature(), allow_number_to_str\u001b[38;5;241m=\u001b[39mallow_number_to_str)\n\u001b[0;32m-> 2144\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt cast array of type\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mto\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfeature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Couldn't cast array of type\nint64\nto\nSequence(feature=Value(dtype='int64', id=None), length=-1, id=None)"
     ]
    }
   ],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(df_train, features=ds_features, split='train')\n",
    "val_ds = datasets.Dataset.from_pandas(df_val, features=ds_features, split='validation')\n",
    "test_ds = datasets.Dataset.from_pandas(df_test, features=ds_features, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19bb3ac9-0c82-46c7-8288-74487b742c82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhf_ObotmczohzMXbBDUBJcPYSbVnErizaEGIo\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvisnrt/mod_capstone\u001b[39m\u001b[38;5;124m'\u001b[39m, token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m      3\u001b[0m val_ds\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvisnrt/mod_capstone\u001b[39m\u001b[38;5;124m'\u001b[39m, token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m      4\u001b[0m test_ds\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpvisnrt/mod_capstone\u001b[39m\u001b[38;5;124m'\u001b[39m, token\u001b[38;5;241m=\u001b[39mtoken)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "token = \"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\"\n",
    "train_ds.push_to_hub('pvisnrt/mod_capstone', token=token)\n",
    "val_ds.push_to_hub('pvisnrt/mod_capstone', token=token)\n",
    "test_ds.push_to_hub('pvisnrt/mod_capstone', token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c7913-54c5-4271-a82f-bdb0f5f0a776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
