{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7378354-8f93-4ebe-9e9c-689d35f1f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4614969d-8568-40ed-ab8a-a05b987cf12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM = 500\n",
    "\n",
    "SEP_TOKEN = \" <SEP> \"\n",
    "EOS_TOKEN = \" <EOS>\"\n",
    "punctuations = ['!',',','.','?',\":\",\";\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3e010dc-ae59-401f-8041-168b1d59bd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def curate_text(text):\n",
    "    curated_text = ''\n",
    "    if type(text) == str:\n",
    "        text = text.replace('\\n',' ')\n",
    "        for punctuation in punctuations:\n",
    "            text = text.replace(punctuation, ' ' + punctuation + ' ')\n",
    "        \n",
    "        curated_text = \" \".join(text.strip().split())\n",
    "    return curated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e013317-9d3d-4ce5-b69a-1b2b6fde3b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_source(row):\n",
    "    source = row['Dialogue']\n",
    "    return source.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bfe290d-3fdf-4434-8e22-469c60e4cb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tgt_sum(row):\n",
    "    tgt_sum = row['Generated Summary']\n",
    "    return tgt_sum.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dafb472-b185-4f9d-a7b1-e399f5800686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tags(row):    \n",
    "    return row['Annotations'].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f8c977-2480-4e51-ae8b-01d29782d1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_count(tokens):\n",
    "    return len(tokens)\n",
    "\n",
    "def map_tag_ids(tags):\n",
    "    return tagLabels.str2int(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a20794-6d00-44a7-a30f-0ab2189a5e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_stratified_into_train_val_test(df_input, frac_train=0.8, frac_val=0.1, frac_test=0.1):\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp = train_test_split(df_input, test_size=(1.0 - frac_train), random_state=42, shuffle=True)\n",
    "\n",
    "    \n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test = train_test_split(df_temp, test_size = relative_frac_test, random_state=42, shuffle=True)\n",
    "    \n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "    \n",
    "    df_train.reset_index(drop=True, inplace = True)\n",
    "    df_val.reset_index(drop=True, inplace = True)\n",
    "    df_test.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    return df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7f7d56f-e592-4fb8-9082-cbb945971350",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('annotated_capstone_data.csv')\n",
    "\n",
    "df = df.iloc[FROM:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720e4cbd-fbcc-48f4-be19-49845985a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Dialogue'] = df['Dialogue'].apply(curate_text)\n",
    "df['Generated Summary'] = df['Generated Summary'].apply(curate_text)\n",
    "df['Annotations'] = df['Annotations'].apply(curate_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7169bb-d902-4af4-a5f1-b570f8c340b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source'] = df.apply(create_source, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7dee49e-8497-45a7-8746-fdf81266f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['summary_target'] = df.apply(create_tgt_sum, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829dcee4-39ea-41ae-8451-c34fd244ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = df.apply(create_tags, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bddfc0a-d751-4448-bd09-c192a7681273",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_labels = np.unique(df['tags'].sum()).tolist()\n",
    "tagLabels = datasets.ClassLabel(num_classes=len(tag_labels), names=tag_labels)\n",
    "\n",
    "df['tag_ids'] = df['tags'].apply(map_tag_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d0bf720-4e55-422f-87af-d21f267ef268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'summary_target': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'tags': Sequence(feature=ClassLabel(names=['C', 'M', 'N', 'O', 'OB', 'W'], id=None), length=-1, id=None)}\n"
     ]
    }
   ],
   "source": [
    "ds_features = datasets.Features({\n",
    "    'source': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None), \n",
    "    'summary_target': datasets.Sequence(feature=datasets.Value(dtype='string', id=None), length=-1, id=None),\n",
    "    'tags': datasets.Sequence(feature=tagLabels, length=-1, id=None)\n",
    "})\n",
    "print(ds_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c468ec2-89b3-48c9-ace0-23d09d220040",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.DataFrame()\n",
    "dataset_df['source'] = df['source']\n",
    "dataset_df['summary_target'] = df['summary_target']\n",
    "dataset_df['tags'] = df['tag_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a1a2e0-acd8-4006-ab9f-131e2511a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary_target</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>[Ethan, :, somethin, for, Scott, &lt;file_photo&gt;,...</td>\n",
       "      <td>[Ethan, and, Marshall, enjoy, making, fun, of,...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>[Ethan, :, somethin, for, Scott, &lt;file_photo&gt;,...</td>\n",
       "      <td>[Ethan, and, Toby, are, making, fun, of, Scott...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, has, a, lot, of, work, to, do, at, work...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, has, only, two, weeks, left, before, he...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>[Igor, :, Shit, ,, I've, got, so, much, to, do...</td>\n",
       "      <td>[Igor, is, demotivated, at, work, ,, because, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[Jack, and, May, are, going, to, have, some, c...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[May, and, Jack, will, have, some, cocktails, ...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[Jack, :, Cocktails, later, ?, May, :, YES, !,...</td>\n",
       "      <td>[May, and, Jack, are, going, for, cocktails, l...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[Margaret, :, Honey, ,, buy, me, some, painkil...</td>\n",
       "      <td>[Jack, will, buy, Margaret, some, painkiller, .]</td>\n",
       "      <td>[3, 0, 0, 3, 3, 3, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[Margaret, :, Honey, ,, buy, me, some, painkil...</td>\n",
       "      <td>[Margaret, has, a, terrible, headache, ., Jack...</td>\n",
       "      <td>[3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "500  [Ethan, :, somethin, for, Scott, <file_photo>,...   \n",
       "501  [Ethan, :, somethin, for, Scott, <file_photo>,...   \n",
       "502  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "503  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "504  [Igor, :, Shit, ,, I've, got, so, much, to, do...   \n",
       "..                                                 ...   \n",
       "595  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "596  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "597  [Jack, :, Cocktails, later, ?, May, :, YES, !,...   \n",
       "598  [Margaret, :, Honey, ,, buy, me, some, painkil...   \n",
       "599  [Margaret, :, Honey, ,, buy, me, some, painkil...   \n",
       "\n",
       "                                        summary_target  \\\n",
       "500  [Ethan, and, Marshall, enjoy, making, fun, of,...   \n",
       "501  [Ethan, and, Toby, are, making, fun, of, Scott...   \n",
       "502  [Igor, has, a, lot, of, work, to, do, at, work...   \n",
       "503  [Igor, has, only, two, weeks, left, before, he...   \n",
       "504  [Igor, is, demotivated, at, work, ,, because, ...   \n",
       "..                                                 ...   \n",
       "595  [Jack, and, May, are, going, to, have, some, c...   \n",
       "596  [May, and, Jack, will, have, some, cocktails, ...   \n",
       "597  [May, and, Jack, are, going, for, cocktails, l...   \n",
       "598   [Jack, will, buy, Margaret, some, painkiller, .]   \n",
       "599  [Margaret, has, a, terrible, headache, ., Jack...   \n",
       "\n",
       "                                                  tags  \n",
       "500                     [3, 3, 3, 3, 3, 3, 3, 3, 3, 1]  \n",
       "501                     [3, 3, 3, 3, 3, 3, 3, 3, 3, 1]  \n",
       "502  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "503  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "504  [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...  \n",
       "..                                                 ...  \n",
       "595            [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  \n",
       "596                     [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  \n",
       "597                     [3, 3, 3, 3, 3, 3, 3, 3, 3, 3]  \n",
       "598                           [3, 0, 0, 3, 3, 3, 3, 1]  \n",
       "599         [3, 3, 3, 3, 3, 3, 3, 0, 0, 3, 3, 3, 3, 1]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dc3a72b-7417-420a-8da3-c62efde33d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_df['summary_target'][500]) == len(dataset_df['tags'][500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e947acca-6967-4963-a5be-d6149d633b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = split_stratified_into_train_val_test(dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba889613-5ad4-4dcb-962f-dad7ff90de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = datasets.Dataset.from_pandas(df_train, features=ds_features, split='train')\n",
    "val_ds = datasets.Dataset.from_pandas(df_val, features=ds_features, split='validation')\n",
    "test_ds = datasets.Dataset.from_pandas(df_test, features=ds_features, split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19bb3ac9-0c82-46c7-8288-74487b742c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11d7e822ef24eab98edca366448df13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf3cba4fa15476ba1f21e5ddd454d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f116b4b87e4765995148e18bb55d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5821858095a4406a749c7739ed92aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d988f5387144c5a9fed86c72929bc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b016b9cd0c3a4d3f9d521b74c9747f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/498 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a3d7cd32694107a114d187e0c3d83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e769eb73aa2a44539fcb517c713b2efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5326245956854433a4cb9760dc4ef467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/611 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token = \"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\"\n",
    "train_ds.push_to_hub('pvisnrt/capstone_hal', token=token)\n",
    "val_ds.push_to_hub('pvisnrt/capstone_hal', token=token)\n",
    "test_ds.push_to_hub('pvisnrt/capstone_hal', token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c7913-54c5-4271-a82f-bdb0f5f0a776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
